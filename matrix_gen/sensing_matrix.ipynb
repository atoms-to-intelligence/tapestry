{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fh\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myloss(theta,i,show=False):\n",
    "    global A\n",
    "    beta = torch.ones([m, n], dtype=torch.float64)*(2**i)\n",
    "    A = torch.sigmoid(beta*theta)\n",
    "    Anorm = torch.sum(A*A,0)**0.5\n",
    "    Anorm = Anorm.repeat(m,1)\n",
    "    A = A/Anorm\n",
    "    M = torch.matmul(torch.t(A), A)\n",
    "    if (show):\n",
    "        print(A)\n",
    "    l1 = torch.norm(M-I)**2\n",
    "    l2 = lam*abs(torch.norm(theta)**2-1)  \n",
    "    return l1+l2,l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2088, 0.2856, 0.2760, 0.2530, 0.2635, 0.2429, 0.2794, 0.2339, 0.2544,\n",
      "         0.2335, 0.3022, 0.2105, 0.2506, 0.2548, 0.2038, 0.2068, 0.2657, 0.2366,\n",
      "         0.2528, 0.2526, 0.2803, 0.2713, 0.2809, 0.2911, 0.2263, 0.2800, 0.2088,\n",
      "         0.2865, 0.2278, 0.2386, 0.2070, 0.3020, 0.2345, 0.2239, 0.2158, 0.2746,\n",
      "         0.2193, 0.2151, 0.2201, 0.2666],\n",
      "        [0.2698, 0.2041, 0.2268, 0.2888, 0.2072, 0.2862, 0.2282, 0.2980, 0.2275,\n",
      "         0.3007, 0.2562, 0.2812, 0.2873, 0.2703, 0.2485, 0.2228, 0.2851, 0.2680,\n",
      "         0.2754, 0.2074, 0.2733, 0.2589, 0.2224, 0.2062, 0.2849, 0.2268, 0.2576,\n",
      "         0.2807, 0.2507, 0.1975, 0.2707, 0.2600, 0.2901, 0.2230, 0.2171, 0.1991,\n",
      "         0.2255, 0.2148, 0.2481, 0.2826],\n",
      "        [0.2705, 0.2133, 0.2131, 0.2684, 0.2579, 0.2859, 0.2365, 0.2213, 0.2695,\n",
      "         0.2180, 0.2190, 0.2583, 0.2322, 0.2408, 0.2422, 0.2811, 0.2718, 0.2205,\n",
      "         0.2760, 0.2458, 0.2012, 0.2823, 0.2260, 0.2874, 0.2905, 0.2340, 0.2725,\n",
      "         0.2038, 0.2806, 0.2537, 0.2576, 0.2616, 0.2117, 0.2609, 0.2909, 0.2022,\n",
      "         0.2277, 0.2891, 0.2438, 0.2427],\n",
      "        [0.2634, 0.2621, 0.2200, 0.2587, 0.2454, 0.2114, 0.2862, 0.2835, 0.2662,\n",
      "         0.2659, 0.2202, 0.2616, 0.2162, 0.2434, 0.2731, 0.2926, 0.2826, 0.2092,\n",
      "         0.2264, 0.2389, 0.2336, 0.2348, 0.2795, 0.2356, 0.2192, 0.2291, 0.2766,\n",
      "         0.2163, 0.2667, 0.2466, 0.2427, 0.2728, 0.2822, 0.2779, 0.2165, 0.2303,\n",
      "         0.2823, 0.2414, 0.2776, 0.2703],\n",
      "        [0.2565, 0.2036, 0.2780, 0.2385, 0.2543, 0.2056, 0.2476, 0.2545, 0.2716,\n",
      "         0.2261, 0.2104, 0.2787, 0.2286, 0.2403, 0.2954, 0.2906, 0.2849, 0.2836,\n",
      "         0.2245, 0.2967, 0.2807, 0.2358, 0.2061, 0.2503, 0.2619, 0.2481, 0.2890,\n",
      "         0.2268, 0.2725, 0.2731, 0.2507, 0.2669, 0.2792, 0.2761, 0.2917, 0.2355,\n",
      "         0.2812, 0.2855, 0.2324, 0.2665],\n",
      "        [0.2229, 0.2535, 0.2401, 0.2136, 0.2646, 0.2874, 0.2009, 0.2785, 0.2165,\n",
      "         0.2299, 0.2731, 0.2718, 0.2494, 0.2337, 0.2619, 0.2161, 0.2587, 0.2826,\n",
      "         0.2382, 0.2280, 0.2350, 0.2186, 0.2814, 0.2862, 0.2737, 0.2547, 0.2821,\n",
      "         0.2809, 0.2467, 0.2657, 0.2097, 0.2499, 0.2363, 0.2597, 0.2198, 0.2853,\n",
      "         0.2311, 0.2933, 0.2588, 0.2298],\n",
      "        [0.2313, 0.2945, 0.2270, 0.2865, 0.2669, 0.2052, 0.2824, 0.2176, 0.2298,\n",
      "         0.2873, 0.2392, 0.2057, 0.2527, 0.2857, 0.2845, 0.2459, 0.2134, 0.2789,\n",
      "         0.2604, 0.2793, 0.2497, 0.2283, 0.2783, 0.2255, 0.2203, 0.2247, 0.2791,\n",
      "         0.2536, 0.2850, 0.2231, 0.2736, 0.2483, 0.2737, 0.2841, 0.2467, 0.2540,\n",
      "         0.2567, 0.2673, 0.2065, 0.2911],\n",
      "        [0.2677, 0.2619, 0.2534, 0.2353, 0.2453, 0.2798, 0.2213, 0.2745, 0.2201,\n",
      "         0.2675, 0.2323, 0.2177, 0.2593, 0.2330, 0.2142, 0.2046, 0.2022, 0.2635,\n",
      "         0.2121, 0.2620, 0.2497, 0.2218, 0.2068, 0.2770, 0.2547, 0.2602, 0.2272,\n",
      "         0.2825, 0.2783, 0.2657, 0.2011, 0.2090, 0.2105, 0.2411, 0.2065, 0.2807,\n",
      "         0.2461, 0.2054, 0.2508, 0.2177],\n",
      "        [0.2752, 0.2122, 0.2734, 0.2488, 0.2655, 0.2730, 0.2763, 0.2102, 0.2347,\n",
      "         0.2104, 0.2775, 0.2659, 0.2733, 0.2549, 0.2325, 0.2702, 0.2105, 0.2121,\n",
      "         0.2468, 0.2168, 0.2356, 0.2664, 0.2724, 0.2581, 0.2301, 0.2939, 0.2268,\n",
      "         0.2376, 0.2009, 0.2559, 0.2552, 0.2295, 0.2162, 0.2029, 0.2537, 0.2590,\n",
      "         0.2417, 0.2173, 0.2616, 0.2131],\n",
      "        [0.2064, 0.2057, 0.2393, 0.2348, 0.2533, 0.2503, 0.1997, 0.2574, 0.2492,\n",
      "         0.2140, 0.2703, 0.2807, 0.2168, 0.2146, 0.2120, 0.2310, 0.2101, 0.2798,\n",
      "         0.2778, 0.2737, 0.2452, 0.2494, 0.2314, 0.2524, 0.2098, 0.2520, 0.2760,\n",
      "         0.2436, 0.2335, 0.2639, 0.2241, 0.2260, 0.2069, 0.2657, 0.2969, 0.2736,\n",
      "         0.2774, 0.2721, 0.2670, 0.2581],\n",
      "        [0.2255, 0.2817, 0.2987, 0.2179, 0.2551, 0.2692, 0.2675, 0.2887, 0.2532,\n",
      "         0.2292, 0.2434, 0.2231, 0.2792, 0.2556, 0.2184, 0.2908, 0.2349, 0.2146,\n",
      "         0.2688, 0.2793, 0.2817, 0.2821, 0.2747, 0.2471, 0.2811, 0.2373, 0.2283,\n",
      "         0.2550, 0.2537, 0.2779, 0.2347, 0.2340, 0.2882, 0.2143, 0.2834, 0.2284,\n",
      "         0.2022, 0.2728, 0.2415, 0.2538],\n",
      "        [0.2718, 0.2251, 0.2635, 0.2352, 0.2587, 0.2415, 0.2710, 0.2236, 0.2194,\n",
      "         0.2812, 0.2642, 0.2751, 0.2394, 0.2292, 0.2547, 0.2685, 0.2311, 0.2547,\n",
      "         0.2697, 0.2264, 0.2404, 0.2553, 0.2359, 0.2071, 0.2147, 0.2959, 0.2057,\n",
      "         0.2813, 0.2454, 0.2132, 0.2802, 0.2179, 0.2563, 0.2206, 0.2494, 0.2255,\n",
      "         0.2723, 0.2173, 0.2660, 0.2509],\n",
      "        [0.2722, 0.2724, 0.2848, 0.2281, 0.2365, 0.2387, 0.2808, 0.2220, 0.2669,\n",
      "         0.2953, 0.2122, 0.2601, 0.2529, 0.2594, 0.2044, 0.2609, 0.2765, 0.2597,\n",
      "         0.2247, 0.2227, 0.2756, 0.2469, 0.2824, 0.2107, 0.2752, 0.2161, 0.2509,\n",
      "         0.2349, 0.2584, 0.2806, 0.2771, 0.2557, 0.2309, 0.2692, 0.2122, 0.2831,\n",
      "         0.2813, 0.2702, 0.2788, 0.2458],\n",
      "        [0.2229, 0.2804, 0.2268, 0.2588, 0.2512, 0.1998, 0.2200, 0.2584, 0.2683,\n",
      "         0.2310, 0.2127, 0.2207, 0.2435, 0.2874, 0.2962, 0.2134, 0.2807, 0.2239,\n",
      "         0.2257, 0.2467, 0.2213, 0.2413, 0.1965, 0.2273, 0.2297, 0.2139, 0.2253,\n",
      "         0.2809, 0.2049, 0.2634, 0.2894, 0.2398, 0.2804, 0.2508, 0.2839, 0.2659,\n",
      "         0.2567, 0.2235, 0.2534, 0.2548],\n",
      "        [0.2397, 0.2762, 0.2184, 0.2566, 0.2257, 0.2784, 0.1990, 0.2395, 0.2719,\n",
      "         0.2107, 0.2909, 0.2457, 0.2906, 0.2592, 0.2729, 0.2631, 0.2406, 0.2812,\n",
      "         0.2590, 0.2710, 0.2448, 0.2181, 0.2220, 0.2446, 0.2902, 0.2450, 0.2586,\n",
      "         0.2028, 0.2572, 0.2207, 0.2355, 0.2088, 0.2236, 0.2563, 0.2631, 0.2417,\n",
      "         0.2658, 0.2414, 0.2396, 0.2032],\n",
      "        [0.2760, 0.2348, 0.2385, 0.2627, 0.2410, 0.2124, 0.2712, 0.2119, 0.2675,\n",
      "         0.2686, 0.2499, 0.2201, 0.2094, 0.2248, 0.2554, 0.2089, 0.2229, 0.2037,\n",
      "         0.2479, 0.2324, 0.2352, 0.2741, 0.2720, 0.2690, 0.2086, 0.2684, 0.2098,\n",
      "         0.2030, 0.2173, 0.2420, 0.2675, 0.2948, 0.2512, 0.2548, 0.2191, 0.2380,\n",
      "         0.2109, 0.2458, 0.2426, 0.2348]], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "hey1\n",
      "tensor(1526.8127, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([[0.2088, 0.2856, 0.2760, 0.2530, 0.2635, 0.2429, 0.2794, 0.2339, 0.2544,\n",
      "         0.2335, 0.3022, 0.2105, 0.2506, 0.2548, 0.2038, 0.2068, 0.2657, 0.2366,\n",
      "         0.2528, 0.2526, 0.2803, 0.2713, 0.2809, 0.2911, 0.2263, 0.2800, 0.2088,\n",
      "         0.2865, 0.2278, 0.2386, 0.2070, 0.3020, 0.2345, 0.2239, 0.2158, 0.2746,\n",
      "         0.2193, 0.2151, 0.2201, 0.2666],\n",
      "        [0.2698, 0.2041, 0.2268, 0.2888, 0.2072, 0.2862, 0.2282, 0.2980, 0.2275,\n",
      "         0.3007, 0.2562, 0.2812, 0.2873, 0.2703, 0.2485, 0.2228, 0.2851, 0.2680,\n",
      "         0.2754, 0.2074, 0.2733, 0.2589, 0.2224, 0.2062, 0.2849, 0.2268, 0.2576,\n",
      "         0.2807, 0.2507, 0.1975, 0.2707, 0.2600, 0.2901, 0.2230, 0.2171, 0.1991,\n",
      "         0.2255, 0.2148, 0.2481, 0.2826],\n",
      "        [0.2705, 0.2133, 0.2131, 0.2684, 0.2579, 0.2859, 0.2365, 0.2213, 0.2695,\n",
      "         0.2180, 0.2190, 0.2583, 0.2322, 0.2408, 0.2422, 0.2811, 0.2718, 0.2205,\n",
      "         0.2760, 0.2458, 0.2012, 0.2823, 0.2260, 0.2874, 0.2905, 0.2340, 0.2725,\n",
      "         0.2038, 0.2806, 0.2537, 0.2576, 0.2616, 0.2117, 0.2609, 0.2909, 0.2022,\n",
      "         0.2277, 0.2891, 0.2438, 0.2427],\n",
      "        [0.2634, 0.2621, 0.2200, 0.2587, 0.2454, 0.2114, 0.2862, 0.2835, 0.2662,\n",
      "         0.2659, 0.2202, 0.2616, 0.2162, 0.2434, 0.2731, 0.2926, 0.2826, 0.2092,\n",
      "         0.2264, 0.2389, 0.2336, 0.2348, 0.2795, 0.2356, 0.2192, 0.2291, 0.2766,\n",
      "         0.2163, 0.2667, 0.2466, 0.2427, 0.2728, 0.2822, 0.2779, 0.2165, 0.2303,\n",
      "         0.2823, 0.2414, 0.2776, 0.2703],\n",
      "        [0.2565, 0.2036, 0.2780, 0.2385, 0.2543, 0.2056, 0.2476, 0.2545, 0.2716,\n",
      "         0.2261, 0.2104, 0.2787, 0.2286, 0.2403, 0.2954, 0.2906, 0.2849, 0.2836,\n",
      "         0.2245, 0.2967, 0.2807, 0.2358, 0.2061, 0.2503, 0.2619, 0.2481, 0.2890,\n",
      "         0.2268, 0.2725, 0.2731, 0.2507, 0.2669, 0.2792, 0.2761, 0.2917, 0.2355,\n",
      "         0.2812, 0.2855, 0.2324, 0.2665],\n",
      "        [0.2229, 0.2535, 0.2401, 0.2136, 0.2646, 0.2874, 0.2009, 0.2785, 0.2165,\n",
      "         0.2299, 0.2731, 0.2718, 0.2494, 0.2337, 0.2619, 0.2161, 0.2587, 0.2826,\n",
      "         0.2382, 0.2280, 0.2350, 0.2186, 0.2814, 0.2862, 0.2737, 0.2547, 0.2821,\n",
      "         0.2809, 0.2467, 0.2657, 0.2097, 0.2499, 0.2363, 0.2597, 0.2198, 0.2853,\n",
      "         0.2311, 0.2933, 0.2588, 0.2298],\n",
      "        [0.2313, 0.2945, 0.2270, 0.2865, 0.2669, 0.2052, 0.2824, 0.2176, 0.2298,\n",
      "         0.2873, 0.2392, 0.2057, 0.2527, 0.2857, 0.2845, 0.2459, 0.2134, 0.2789,\n",
      "         0.2604, 0.2793, 0.2497, 0.2283, 0.2783, 0.2255, 0.2203, 0.2247, 0.2791,\n",
      "         0.2536, 0.2850, 0.2231, 0.2736, 0.2483, 0.2737, 0.2841, 0.2467, 0.2540,\n",
      "         0.2567, 0.2673, 0.2065, 0.2911],\n",
      "        [0.2677, 0.2619, 0.2534, 0.2353, 0.2453, 0.2798, 0.2213, 0.2745, 0.2201,\n",
      "         0.2675, 0.2323, 0.2177, 0.2593, 0.2330, 0.2142, 0.2046, 0.2022, 0.2635,\n",
      "         0.2121, 0.2620, 0.2497, 0.2218, 0.2068, 0.2770, 0.2547, 0.2602, 0.2272,\n",
      "         0.2825, 0.2783, 0.2657, 0.2011, 0.2090, 0.2105, 0.2411, 0.2065, 0.2807,\n",
      "         0.2461, 0.2054, 0.2508, 0.2177],\n",
      "        [0.2752, 0.2122, 0.2734, 0.2488, 0.2655, 0.2730, 0.2763, 0.2102, 0.2347,\n",
      "         0.2104, 0.2775, 0.2659, 0.2733, 0.2549, 0.2325, 0.2702, 0.2105, 0.2121,\n",
      "         0.2468, 0.2168, 0.2356, 0.2664, 0.2724, 0.2581, 0.2301, 0.2939, 0.2268,\n",
      "         0.2376, 0.2009, 0.2559, 0.2552, 0.2295, 0.2162, 0.2029, 0.2537, 0.2590,\n",
      "         0.2417, 0.2173, 0.2616, 0.2131],\n",
      "        [0.2064, 0.2057, 0.2393, 0.2348, 0.2533, 0.2503, 0.1997, 0.2574, 0.2492,\n",
      "         0.2140, 0.2703, 0.2807, 0.2168, 0.2146, 0.2120, 0.2310, 0.2101, 0.2798,\n",
      "         0.2778, 0.2737, 0.2452, 0.2494, 0.2314, 0.2524, 0.2098, 0.2520, 0.2760,\n",
      "         0.2436, 0.2335, 0.2639, 0.2241, 0.2260, 0.2069, 0.2657, 0.2969, 0.2736,\n",
      "         0.2774, 0.2721, 0.2670, 0.2581],\n",
      "        [0.2255, 0.2817, 0.2987, 0.2179, 0.2551, 0.2692, 0.2675, 0.2887, 0.2532,\n",
      "         0.2292, 0.2434, 0.2231, 0.2792, 0.2556, 0.2184, 0.2908, 0.2349, 0.2146,\n",
      "         0.2688, 0.2793, 0.2817, 0.2821, 0.2747, 0.2471, 0.2811, 0.2373, 0.2283,\n",
      "         0.2550, 0.2537, 0.2779, 0.2347, 0.2340, 0.2882, 0.2143, 0.2834, 0.2284,\n",
      "         0.2022, 0.2728, 0.2415, 0.2538],\n",
      "        [0.2718, 0.2251, 0.2635, 0.2352, 0.2587, 0.2415, 0.2710, 0.2236, 0.2194,\n",
      "         0.2812, 0.2642, 0.2751, 0.2394, 0.2292, 0.2547, 0.2685, 0.2311, 0.2547,\n",
      "         0.2697, 0.2264, 0.2404, 0.2553, 0.2359, 0.2071, 0.2147, 0.2959, 0.2057,\n",
      "         0.2813, 0.2454, 0.2132, 0.2802, 0.2179, 0.2563, 0.2206, 0.2494, 0.2255,\n",
      "         0.2723, 0.2173, 0.2660, 0.2509],\n",
      "        [0.2722, 0.2724, 0.2848, 0.2281, 0.2365, 0.2387, 0.2808, 0.2220, 0.2669,\n",
      "         0.2953, 0.2122, 0.2601, 0.2529, 0.2594, 0.2044, 0.2609, 0.2765, 0.2597,\n",
      "         0.2247, 0.2227, 0.2756, 0.2469, 0.2824, 0.2107, 0.2752, 0.2161, 0.2509,\n",
      "         0.2349, 0.2584, 0.2806, 0.2771, 0.2557, 0.2309, 0.2692, 0.2122, 0.2831,\n",
      "         0.2813, 0.2702, 0.2788, 0.2458],\n",
      "        [0.2229, 0.2804, 0.2268, 0.2588, 0.2512, 0.1998, 0.2200, 0.2584, 0.2683,\n",
      "         0.2310, 0.2127, 0.2207, 0.2435, 0.2874, 0.2962, 0.2134, 0.2807, 0.2239,\n",
      "         0.2257, 0.2467, 0.2213, 0.2413, 0.1965, 0.2273, 0.2297, 0.2139, 0.2253,\n",
      "         0.2809, 0.2049, 0.2634, 0.2894, 0.2398, 0.2804, 0.2508, 0.2839, 0.2659,\n",
      "         0.2567, 0.2235, 0.2534, 0.2548],\n",
      "        [0.2397, 0.2762, 0.2184, 0.2566, 0.2257, 0.2784, 0.1990, 0.2395, 0.2719,\n",
      "         0.2107, 0.2909, 0.2457, 0.2906, 0.2592, 0.2729, 0.2631, 0.2406, 0.2812,\n",
      "         0.2590, 0.2710, 0.2448, 0.2181, 0.2220, 0.2446, 0.2902, 0.2450, 0.2586,\n",
      "         0.2028, 0.2572, 0.2207, 0.2355, 0.2088, 0.2236, 0.2563, 0.2631, 0.2417,\n",
      "         0.2658, 0.2414, 0.2396, 0.2032],\n",
      "        [0.2760, 0.2348, 0.2385, 0.2627, 0.2410, 0.2124, 0.2712, 0.2119, 0.2675,\n",
      "         0.2686, 0.2499, 0.2201, 0.2094, 0.2248, 0.2554, 0.2089, 0.2229, 0.2037,\n",
      "         0.2479, 0.2324, 0.2352, 0.2741, 0.2720, 0.2690, 0.2086, 0.2684, 0.2098,\n",
      "         0.2030, 0.2173, 0.2420, 0.2675, 0.2948, 0.2512, 0.2548, 0.2191, 0.2380,\n",
      "         0.2109, 0.2458, 0.2426, 0.2348]], dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<DivBackward0>)\n",
      "hey2\n"
     ]
    }
   ],
   "source": [
    "m = 16\n",
    "n = 40\n",
    "I = torch.eye(n, dtype=torch.float64)\n",
    "lam = 0.01\n",
    "\n",
    "# beta = torch.ones([m, n], dtype=torch.float64, requires_grad=True)\n",
    "x = torch.rand([m, n], dtype=torch.float64, requires_grad=True)\n",
    "# print(x)\n",
    "# x=x-0.5\n",
    "# print(x)\n",
    "# temp = torch.norm(x)\n",
    "# x.data = x.data/temp\n",
    "\n",
    "# y, fnorm = myloss(x,0,True)\n",
    "# print(\"hey1\")\n",
    "# print(y)\n",
    "# print(A)\n",
    "# print(\"hey2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 1  epoch: 1000  loss: 964.7941201048086  F-norm: 951.7792066181577\n",
      "tensor([[0.1044, 0.3389, 0.3561, 0.3192, 0.3173, 0.1125, 0.3360, 0.1113, 0.3195,\n",
      "         0.1103, 0.3456, 0.1011, 0.1261, 0.3538, 0.0982, 0.0999, 0.3340, 0.1095,\n",
      "         0.3191, 0.3543, 0.3786, 0.3348, 0.3362, 0.3600, 0.1081, 0.3560, 0.1013,\n",
      "         0.3797, 0.1130, 0.1101, 0.1004, 0.3881, 0.1085, 0.1009, 0.1071, 0.3550,\n",
      "         0.1066, 0.1034, 0.1095, 0.3345],\n",
      "        [0.3343, 0.0983, 0.1097, 0.3216, 0.1014, 0.3378, 0.1103, 0.3625, 0.1084,\n",
      "         0.3632, 0.3365, 0.3202, 0.4092, 0.3543, 0.1115, 0.1061, 0.3375, 0.3169,\n",
      "         0.3167, 0.1038, 0.3766, 0.3351, 0.1090, 0.1046, 0.3369, 0.1105, 0.3352,\n",
      "         0.3775, 0.1171, 0.0955, 0.3340, 0.3763, 0.3383, 0.1009, 0.1079, 0.1029,\n",
      "         0.1091, 0.1035, 0.1172, 0.3373],\n",
      "        [0.3360, 0.1026, 0.1054, 0.3183, 0.3198, 0.3393, 0.1126, 0.1086, 0.3187,\n",
      "         0.1067, 0.1027, 0.3198, 0.1271, 0.1130, 0.1102, 0.3373, 0.3353, 0.1050,\n",
      "         0.3200, 0.1138, 0.1103, 0.3391, 0.1102, 0.3595, 0.3406, 0.1123, 0.3354,\n",
      "         0.1108, 0.3571, 0.3215, 0.3362, 0.3765, 0.1019, 0.3061, 0.3590, 0.1047,\n",
      "         0.1098, 0.3398, 0.1161, 0.1106],\n",
      "        [0.3363, 0.3373, 0.1086, 0.3205, 0.1154, 0.1047, 0.3396, 0.3588, 0.3192,\n",
      "         0.3552, 0.1041, 0.3209, 0.1236, 0.1147, 0.3346, 0.3416, 0.3380, 0.1009,\n",
      "         0.1075, 0.1149, 0.1239, 0.1108, 0.3374, 0.1165, 0.1067, 0.1125, 0.3371,\n",
      "         0.1169, 0.3545, 0.1135, 0.1127, 0.3787, 0.3371, 0.3067, 0.1086, 0.1168,\n",
      "         0.3393, 0.1122, 0.3386, 0.3363],\n",
      "        [0.1225, 0.0998, 0.3601, 0.1120, 0.1204, 0.1029, 0.1193, 0.1191, 0.3214,\n",
      "         0.1121, 0.1019, 0.3228, 0.1307, 0.1177, 0.3427, 0.3411, 0.3397, 0.3233,\n",
      "         0.1087, 0.3642, 0.3810, 0.1136, 0.1044, 0.1223, 0.3391, 0.1196, 0.3411,\n",
      "         0.1236, 0.3569, 0.3231, 0.1177, 0.3808, 0.3384, 0.3071, 0.3605, 0.1210,\n",
      "         0.3400, 0.3395, 0.1177, 0.3395],\n",
      "        [0.1115, 0.1119, 0.1133, 0.1016, 0.3200, 0.3407, 0.1007, 0.3575, 0.1052,\n",
      "         0.1112, 0.3382, 0.3212, 0.1283, 0.1133, 0.3368, 0.1049, 0.3366, 0.3235,\n",
      "         0.1108, 0.1122, 0.1240, 0.1057, 0.3391, 0.3596, 0.3371, 0.3561, 0.3396,\n",
      "         0.3793, 0.1174, 0.3212, 0.1030, 0.1169, 0.1107, 0.3099, 0.1097, 0.3596,\n",
      "         0.1115, 0.3429, 0.3366, 0.1093],\n",
      "        [0.1164, 0.3455, 0.1128, 0.3260, 0.3234, 0.1035, 0.3409, 0.1100, 0.1116,\n",
      "         0.3617, 0.1110, 0.1015, 0.1310, 0.3619, 0.3407, 0.1145, 0.1081, 0.3248,\n",
      "         0.3236, 0.3602, 0.1274, 0.1108, 0.3398, 0.1156, 0.1091, 0.1130, 0.3406,\n",
      "         0.1266, 0.3608, 0.1093, 0.3400, 0.1194, 0.3388, 0.3134, 0.1183, 0.1218,\n",
      "         0.1165, 0.3389, 0.1069, 0.3445],\n",
      "        [0.3322, 0.3303, 0.3493, 0.1028, 0.3148, 0.3344, 0.1044, 0.3521, 0.1023,\n",
      "         0.3508, 0.1019, 0.1008, 0.3980, 0.1066, 0.0998, 0.0966, 0.0984, 0.3135,\n",
      "         0.0986, 0.3495, 0.3694, 0.1021, 0.1000, 0.3534, 0.3289, 0.3491, 0.1040,\n",
      "         0.3766, 0.3542, 0.3150, 0.0962, 0.1049, 0.0988, 0.1004, 0.1009, 0.3548,\n",
      "         0.3314, 0.0973, 0.3299, 0.1012],\n",
      "        [0.3351, 0.1004, 0.3543, 0.3180, 0.3160, 0.3335, 0.3346, 0.1028, 0.1077,\n",
      "         0.1021, 0.3351, 0.3168, 0.4034, 0.3517, 0.1062, 0.3330, 0.1031, 0.1002,\n",
      "         0.1071, 0.1058, 0.1191, 0.3325, 0.3333, 0.3506, 0.1070, 0.3607, 0.1061,\n",
      "         0.1184, 0.1019, 0.3171, 0.3327, 0.1117, 0.1021, 0.0923, 0.3504, 0.3511,\n",
      "         0.1094, 0.1028, 0.3326, 0.1014],\n",
      "        [0.1024, 0.0980, 0.1094, 0.1051, 0.3155, 0.3333, 0.0980, 0.3512, 0.3180,\n",
      "         0.1037, 0.3327, 0.3199, 0.1201, 0.1049, 0.1003, 0.1065, 0.1027, 0.3191,\n",
      "         0.3183, 0.3534, 0.1200, 0.3343, 0.1098, 0.3512, 0.1006, 0.3517, 0.3342,\n",
      "         0.1193, 0.1123, 0.3156, 0.1056, 0.1113, 0.0988, 0.3009, 0.3602, 0.3533,\n",
      "         0.3358, 0.3323, 0.3331, 0.3329],\n",
      "        [0.1148, 0.3424, 0.3671, 0.1051, 0.1180, 0.3397, 0.3397, 0.3630, 0.1167,\n",
      "         0.1134, 0.1121, 0.1094, 0.4089, 0.1166, 0.1074, 0.3438, 0.1168, 0.1054,\n",
      "         0.3238, 0.3602, 0.3818, 0.3426, 0.3398, 0.1202, 0.3407, 0.1166, 0.1118,\n",
      "         0.1268, 0.1198, 0.3258, 0.1139, 0.1191, 0.3434, 0.1006, 0.3598, 0.1185,\n",
      "         0.1025, 0.3398, 0.1200, 0.1149],\n",
      "        [0.3358, 0.1058, 0.3547, 0.1062, 0.3185, 0.1115, 0.3350, 0.1085, 0.1050,\n",
      "         0.3570, 0.3354, 0.3208, 0.1258, 0.1100, 0.3347, 0.3352, 0.1111, 0.3200,\n",
      "         0.3191, 0.1101, 0.1214, 0.3355, 0.1117, 0.1049, 0.1041, 0.3630, 0.1001,\n",
      "         0.3784, 0.1142, 0.1023, 0.3380, 0.1103, 0.3343, 0.0997, 0.1127, 0.1131,\n",
      "         0.3368, 0.1042, 0.3352, 0.3358],\n",
      "        [0.3351, 0.3342, 0.3581, 0.1068, 0.1142, 0.1145, 0.3355, 0.1098, 0.3174,\n",
      "         0.3607, 0.1011, 0.3207, 0.1317, 0.3561, 0.0990, 0.3356, 0.3348, 0.3208,\n",
      "         0.1073, 0.1107, 0.3777, 0.1141, 0.3358, 0.1074, 0.3341, 0.1078, 0.1152,\n",
      "         0.1240, 0.3548, 0.3197, 0.3355, 0.1194, 0.1096, 0.2984, 0.1066, 0.3577,\n",
      "         0.3369, 0.3339, 0.3369, 0.1138],\n",
      "        [0.1095, 0.3391, 0.1082, 0.3186, 0.3188, 0.0986, 0.1067, 0.3532, 0.3196,\n",
      "         0.1085, 0.1000, 0.1044, 0.1232, 0.3607, 0.3439, 0.1023, 0.3382, 0.1050,\n",
      "         0.1053, 0.1100, 0.1178, 0.1078, 0.0980, 0.1113, 0.1079, 0.1055, 0.1061,\n",
      "         0.3785, 0.1043, 0.3201, 0.3425, 0.1127, 0.3382, 0.3087, 0.3577, 0.3539,\n",
      "         0.3348, 0.1056, 0.3343, 0.3347],\n",
      "        [0.1143, 0.3384, 0.1072, 0.3202, 0.1090, 0.3383, 0.0994, 0.1118, 0.3210,\n",
      "         0.1042, 0.3437, 0.1105, 0.4115, 0.3545, 0.3364, 0.3355, 0.1130, 0.3234,\n",
      "         0.3198, 0.3556, 0.1213, 0.1049, 0.1090, 0.1147, 0.3417, 0.1124, 0.3354,\n",
      "         0.1107, 0.3532, 0.1053, 0.1099, 0.1079, 0.1059, 0.3090, 0.3530, 0.1165,\n",
      "         0.3366, 0.1097, 0.1146, 0.0992],\n",
      "        [0.3375, 0.1051, 0.1068, 0.3179, 0.1072, 0.1030, 0.3353, 0.1041, 0.3196,\n",
      "         0.3540, 0.3348, 0.1031, 0.1183, 0.1069, 0.3329, 0.0999, 0.1069, 0.0976,\n",
      "         0.3178, 0.1083, 0.1171, 0.3372, 0.3354, 0.3541, 0.1012, 0.3542, 0.1008,\n",
      "         0.1094, 0.1080, 0.1059, 0.3351, 0.3859, 0.3330, 0.3070, 0.1069, 0.1118,\n",
      "         0.1028, 0.3336, 0.1095, 0.1049]], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "beta: 1  epoch: 2000  loss: 656.0454962534695  F-norm: 630.0738607890975\n",
      "beta: 1  epoch: 3000  loss: 546.1249397559005  F-norm: 510.6816613100393\n",
      "beta: 1  epoch: 4000  loss: 480.34780963439874  F-norm: 437.33129258590367\n",
      "beta: 1  epoch: 5000  loss: 413.61514740806325  F-norm: 363.24149270332765\n",
      "beta: 1  epoch: 6000  loss: 347.77447631372684  F-norm: 290.7489157968139\n",
      "beta: 1  epoch: 7000  loss: 286.55697855095417  F-norm: 224.15151443499974\n",
      "beta: 1  epoch: 8000  loss: 240.62613532007094  F-norm: 175.46078616856235\n",
      "beta: 1  epoch: 9000  loss: 207.93356035623668  F-norm: 142.36459167310687\n",
      "beta: 1  epoch: 10000  loss: 187.742520237703  F-norm: 122.57740412776039\n",
      "beta: 1  epoch: 11000  loss: 175.57104004239363  F-norm: 110.88050940378692\n",
      "beta: 1  epoch: 12000  loss: 169.70275331579802  F-norm: 105.60145587778266\n",
      "beta: 1  epoch: 13000  loss: 167.0644904824166  F-norm: 102.98514654465792\n",
      "beta: 1  epoch: 14000  loss: 166.36691781061222  F-norm: 102.21781491160779\n",
      "beta: 1  epoch: 15000  loss: 166.22809592682253  F-norm: 101.98739564844978\n",
      "beta: 1  epoch: 16000  loss: 166.20329392676086  F-norm: 101.92349964404511\n",
      "beta: 1  epoch: 17000  loss: 166.20021739599747  F-norm: 101.90838509086099\n",
      "beta: 1  epoch: 18000  loss: 166.20006229643212  F-norm: 101.90555765556192\n",
      "beta: 1  epoch: 19000  loss: 166.2000607934085  F-norm: 101.90530584862219\n",
      "beta: 1  epoch: 20000  loss: 166.20006079253122  F-norm: 101.90530068264594\n",
      "beta: 1  epoch: 21000  loss: 166.2000607925311  F-norm: 101.90530067358935\n",
      "beta: 1  epoch: 22000  loss: 166.2000607925311  F-norm: 101.90530067358917\n",
      "beta: 1  epoch: 23000  loss: 166.20006079253113  F-norm: 101.90530067358921\n",
      "beta: 1  epoch: 24000  loss: 166.2000607925312  F-norm: 101.90530067358921\n",
      "beta: 1  epoch: 25000  loss: 166.2000607925313  F-norm: 101.9053006723792\n",
      "beta: 1  epoch: 26000  loss: 166.2000607973602  F-norm: 101.90529564905134\n",
      "beta: 1  epoch: 27000  loss: 166.2000607937772  F-norm: 101.90528779488957\n",
      "beta: 1  epoch: 28000  loss: 166.2000609035224  F-norm: 101.90368800020575\n",
      "beta: 1  epoch: 29000  loss: 166.2000607925313  F-norm: 101.90530073771603\n",
      "beta: 1  epoch: 30000  loss: 166.20006079253096  F-norm: 101.90530059686544\n",
      "beta: 1  epoch: 31000  loss: 166.20006079314425  F-norm: 101.90515937257862\n",
      "beta: 1  epoch: 32000  loss: 166.2000607925315  F-norm: 101.90530066256713\n",
      "beta: 1  epoch: 33000  loss: 166.20006079253113  F-norm: 101.90530065580612\n",
      "beta: 1  epoch: 34000  loss: 166.20006079347138  F-norm: 101.9051210719506\n",
      "beta: 1  epoch: 35000  loss: 166.20006079253133  F-norm: 101.90530025925803\n",
      "beta: 1  epoch: 36000  loss: 166.20006079253133  F-norm: 101.90530067077148\n",
      "beta: 1  epoch: 37000  loss: 166.20006079253116  F-norm: 101.90530055803833\n",
      "beta: 1  epoch: 38000  loss: 166.20006079253156  F-norm: 101.90530086746598\n",
      "beta: 1  epoch: 39000  loss: 166.20006079253133  F-norm: 101.9053007091182\n",
      "beta: 1  epoch: 40000  loss: 166.2000607925313  F-norm: 101.90530067545083\n",
      "beta: 2  epoch: 1000  loss: 166.20006079253136  F-norm: 101.90530067351641\n",
      "tensor([[0.0247, 0.0341, 0.7025, 0.0188, 0.0235, 0.0245, 0.0235, 0.0381, 0.7027,\n",
      "         0.0336, 0.0395, 0.0335, 0.0239, 0.0239, 0.0343, 0.0341, 0.7026, 0.0237,\n",
      "         0.0344, 0.0343, 0.0344, 0.0349, 0.0187, 0.0344, 0.0187, 0.0340, 0.0237,\n",
      "         0.0350, 0.0241, 0.0358, 0.0238, 0.7026, 0.0349, 0.0240, 0.0349, 0.0342,\n",
      "         0.0343, 0.0240, 0.0188, 0.7023],\n",
      "        [0.0243, 0.0358, 0.0351, 0.0358, 0.0359, 0.0243, 0.0361, 0.9897, 0.0352,\n",
      "         0.7052, 0.0417, 0.7057, 0.0361, 0.0368, 0.0242, 0.0365, 0.0353, 0.0243,\n",
      "         0.0360, 0.0243, 0.0243, 0.7053, 0.0361, 0.0242, 0.0360, 0.0246, 0.0361,\n",
      "         0.0359, 0.0243, 0.0246, 0.0361, 0.0352, 0.0358, 0.0360, 0.0242, 0.0366,\n",
      "         0.0360, 0.0243, 0.0360, 0.0354],\n",
      "        [0.7034, 0.0343, 0.0370, 0.0184, 0.0238, 0.7033, 0.0235, 0.0234, 0.0242,\n",
      "         0.0238, 0.0408, 0.0235, 0.0237, 0.0240, 0.0355, 0.0237, 0.0356, 0.0343,\n",
      "         0.0344, 0.0343, 0.0344, 0.6996, 0.0236, 0.0349, 0.0242, 0.0237, 0.0343,\n",
      "         0.0344, 0.7029, 0.7030, 0.0235, 0.0242, 0.0342, 0.0343, 0.0343, 0.0235,\n",
      "         0.0343, 0.0364, 0.0242, 0.0241],\n",
      "        [0.7022, 0.0335, 0.0188, 0.7025, 0.0342, 0.0187, 0.0343, 0.0394, 0.0189,\n",
      "         0.0343, 0.0381, 0.0343, 0.0241, 0.0242, 0.0335, 0.0342, 0.0187, 0.0237,\n",
      "         0.0337, 0.0344, 0.0337, 0.0236, 0.7026, 0.0344, 0.0188, 0.0348, 0.0237,\n",
      "         0.0343, 0.0240, 0.0240, 0.0351, 0.7025, 0.0336, 0.0237, 0.0342, 0.0351,\n",
      "         0.0343, 0.0239, 0.7025, 0.0245],\n",
      "        [0.0344, 0.0186, 0.0337, 0.0343, 0.0342, 0.0344, 0.0241, 0.0234, 0.0343,\n",
      "         0.0235, 0.0383, 0.6994, 0.0239, 0.0331, 0.0336, 0.0329, 0.0237, 0.7030,\n",
      "         0.0244, 0.7030, 0.7030, 0.0235, 0.0237, 0.0359, 0.0337, 0.0337, 0.0243,\n",
      "         0.0188, 0.0351, 0.0338, 0.0244, 0.0342, 0.0188, 0.0187, 0.7029, 0.0350,\n",
      "         0.0244, 0.0338, 0.0337, 0.0351],\n",
      "        [0.0237, 0.0368, 0.0239, 0.0239, 0.0342, 0.0348, 0.0364, 0.0395, 0.0239,\n",
      "         0.0344, 0.0382, 0.0237, 0.0366, 0.0352, 0.0336, 0.0336, 0.7028, 0.7025,\n",
      "         0.0241, 0.0242, 0.0242, 0.0342, 0.7028, 0.0235, 0.0354, 0.0343, 0.7027,\n",
      "         0.0242, 0.0350, 0.0344, 0.0240, 0.0185, 0.0242, 0.7029, 0.0184, 0.0235,\n",
      "         0.0241, 0.0352, 0.0239, 0.0240],\n",
      "        [0.0238, 0.0239, 0.0234, 0.0354, 0.6996, 0.0238, 0.7032, 0.0394, 0.0238,\n",
      "         0.0343, 0.0234, 0.0349, 0.0359, 0.0351, 0.0235, 0.0238, 0.0237, 0.0356,\n",
      "         0.0237, 0.0355, 0.0239, 0.0234, 0.0356, 0.0342, 0.0348, 0.0349, 0.0349,\n",
      "         0.0239, 0.7028, 0.0238, 0.7033, 0.0237, 0.0185, 0.0240, 0.0239, 0.0350,\n",
      "         0.0348, 0.0343, 0.0348, 0.7034],\n",
      "        [0.0342, 0.7025, 0.0341, 0.0235, 0.0342, 0.0235, 0.0244, 0.0394, 0.0235,\n",
      "         0.0343, 0.0382, 0.0239, 0.7028, 0.0345, 0.0336, 0.0336, 0.0357, 0.0244,\n",
      "         0.0187, 0.7024, 0.0188, 0.0342, 0.0358, 0.0237, 0.0235, 0.0343, 0.0243,\n",
      "         0.7026, 0.0351, 0.0345, 0.0241, 0.0340, 0.0188, 0.0244, 0.0186, 0.0237,\n",
      "         0.7025, 0.0345, 0.0342, 0.0350],\n",
      "        [0.0238, 0.0342, 0.0236, 0.0354, 0.0240, 0.0238, 0.0352, 0.0406, 0.0348,\n",
      "         0.0245, 0.0236, 0.0343, 0.0352, 0.7033, 0.0187, 0.6996, 0.0342, 0.0338,\n",
      "         0.0237, 0.0337, 0.0337, 0.0237, 0.0351, 0.0187, 0.0240, 0.7023, 0.0237,\n",
      "         0.0337, 0.0238, 0.7028, 0.0344, 0.0347, 0.0336, 0.0337, 0.0329, 0.7031,\n",
      "         0.0237, 0.0187, 0.0240, 0.0351],\n",
      "        [0.0344, 0.0184, 0.0350, 0.0342, 0.0349, 0.0343, 0.0236, 0.0392, 0.0343,\n",
      "         0.0237, 0.0408, 0.0356, 0.0237, 0.0240, 0.0240, 0.0239, 0.0235, 0.0241,\n",
      "         0.7030, 0.0242, 0.0243, 0.0342, 0.0235, 0.7022, 0.0350, 0.0185, 0.7029,\n",
      "         0.0243, 0.0343, 0.0238, 0.0356, 0.0342, 0.0242, 0.0241, 0.0370, 0.7023,\n",
      "         0.7029, 0.0240, 0.0351, 0.0343],\n",
      "        [0.0337, 0.7025, 0.0337, 0.0336, 0.0237, 0.0344, 0.7022, 0.0393, 0.0343,\n",
      "         0.0343, 0.0394, 0.0239, 0.0242, 0.0338, 0.0343, 0.0343, 0.0358, 0.0244,\n",
      "         0.7025, 0.0188, 0.7024, 0.0342, 0.0350, 0.0237, 0.0337, 0.0342, 0.0243,\n",
      "         0.0189, 0.0237, 0.0346, 0.0187, 0.0336, 0.7026, 0.0247, 0.0188, 0.0237,\n",
      "         0.0187, 0.0339, 0.0330, 0.0237],\n",
      "        [0.0361, 0.0352, 0.0369, 0.0344, 0.7055, 0.0361, 0.0243, 0.0416, 0.0353,\n",
      "         0.0244, 0.9898, 0.0352, 0.0346, 0.0247, 0.7051, 0.7053, 0.0353, 0.0347,\n",
      "         0.0369, 0.0346, 0.0354, 0.0367, 0.0345, 0.0248, 0.0360, 0.0189, 0.0362,\n",
      "         0.0354, 0.0246, 0.0248, 0.0243, 0.0352, 0.0359, 0.0354, 0.0354, 0.0247,\n",
      "         0.0361, 0.0248, 0.0360, 0.0243],\n",
      "        [0.0245, 0.0337, 0.7027, 0.0187, 0.0349, 0.0245, 0.0336, 0.0393, 0.0187,\n",
      "         0.0237, 0.0408, 0.0336, 0.0239, 0.7023, 0.0239, 0.0239, 0.0242, 0.0344,\n",
      "         0.0345, 0.0338, 0.0332, 0.0356, 0.0241, 0.0240, 0.7027, 0.0185, 0.0359,\n",
      "         0.0338, 0.0358, 0.0243, 0.0337, 0.0187, 0.0331, 0.0344, 0.0331, 0.0239,\n",
      "         0.0351, 0.7021, 0.7028, 0.0239],\n",
      "        [0.0344, 0.0188, 0.0344, 0.0342, 0.0237, 0.0344, 0.0187, 0.0394, 0.0350,\n",
      "         0.0336, 0.0396, 0.0241, 0.0239, 0.0331, 0.0337, 0.0337, 0.0240, 0.0187,\n",
      "         0.0247, 0.0188, 0.0189, 0.0343, 0.0236, 0.0351, 0.0336, 0.0330, 0.0243,\n",
      "         0.7027, 0.0237, 0.0338, 0.7022, 0.0349, 0.7026, 0.7027, 0.7022, 0.0351,\n",
      "         0.0245, 0.0332, 0.0337, 0.0240],\n",
      "        [0.0187, 0.0235, 0.0187, 0.7025, 0.0342, 0.7022, 0.0351, 0.0394, 0.7026,\n",
      "         0.0343, 0.0381, 0.0343, 0.7028, 0.0242, 0.0335, 0.0342, 0.0241, 0.0350,\n",
      "         0.0342, 0.0235, 0.0343, 0.0237, 0.0244, 0.0343, 0.7025, 0.0349, 0.0350,\n",
      "         0.0235, 0.0240, 0.0240, 0.0351, 0.0188, 0.0341, 0.0350, 0.0341, 0.0350,\n",
      "         0.0235, 0.0239, 0.0188, 0.0242],\n",
      "        [0.0350, 0.0341, 0.0237, 0.0340, 0.0237, 0.0350, 0.0343, 0.0234, 0.0341,\n",
      "         0.6999, 0.0236, 0.0235, 0.0344, 0.0187, 0.6999, 0.0187, 0.0344, 0.0344,\n",
      "         0.0237, 0.0344, 0.0344, 0.0237, 0.0343, 0.7034, 0.0236, 0.7028, 0.0237,\n",
      "         0.0337, 0.0350, 0.0245, 0.0336, 0.0341, 0.0336, 0.0337, 0.0336, 0.0187,\n",
      "         0.0237, 0.7035, 0.0237, 0.0344]], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "beta: 2  epoch: 2000  loss: 166.2000607925312  F-norm: 101.90530067364107\n",
      "beta: 2  epoch: 3000  loss: 166.2000607925312  F-norm: 101.90530067347753\n",
      "beta: 2  epoch: 4000  loss: 166.20006079253145  F-norm: 101.90530064029265\n",
      "beta: 2  epoch: 5000  loss: 166.2000615956863  F-norm: 101.91055305070721\n",
      "beta: 2  epoch: 6000  loss: 166.20006083221773  F-norm: 101.90646815308087\n",
      "beta: 2  epoch: 7000  loss: 166.20006080722322  F-norm: 101.90459035857518\n",
      "beta: 2  epoch: 8000  loss: 166.20006081945394  F-norm: 101.90626230097962\n",
      "beta: 2  epoch: 9000  loss: 166.20006079253548  F-norm: 101.90528896860174\n",
      "beta: 2  epoch: 10000  loss: 166.20006079253136  F-norm: 101.90530042853014\n",
      "beta: 2  epoch: 11000  loss: 166.20006079253147  F-norm: 101.90530065599111\n",
      "beta: 2  epoch: 12000  loss: 166.20006079253136  F-norm: 101.90530067506748\n",
      "beta: 2  epoch: 13000  loss: 166.20006079253125  F-norm: 101.90530067359344\n",
      "beta: 2  epoch: 14000  loss: 166.2000607925313  F-norm: 101.9053006735806\n",
      "beta: 2  epoch: 15000  loss: 166.20006079253136  F-norm: 101.90530093945462\n",
      "beta: 2  epoch: 16000  loss: 166.20006081944652  F-norm: 101.90626213291142\n",
      "beta: 2  epoch: 17000  loss: 166.2000607925985  F-norm: 101.90534871835926\n",
      "beta: 2  epoch: 18000  loss: 166.20006079253142  F-norm: 101.90529911796888\n",
      "beta: 2  epoch: 19000  loss: 166.20006079253125  F-norm: 101.90530067064603\n",
      "beta: 2  epoch: 20000  loss: 166.2000607925315  F-norm: 101.9053006748309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 2  epoch: 21000  loss: 166.20006079253133  F-norm: 101.90530067497097\n",
      "beta: 2  epoch: 22000  loss: 166.20006079253125  F-norm: 101.90530067327396\n",
      "beta: 2  epoch: 23000  loss: 166.20006079253136  F-norm: 101.90530067420377\n",
      "beta: 2  epoch: 24000  loss: 166.20006079253147  F-norm: 101.90530067429849\n",
      "beta: 2  epoch: 25000  loss: 166.20006079253142  F-norm: 101.90530067162027\n",
      "beta: 2  epoch: 26000  loss: 166.20006079253116  F-norm: 101.90530067566709\n",
      "beta: 2  epoch: 27000  loss: 166.2000607925313  F-norm: 101.90530070579844\n",
      "beta: 2  epoch: 28000  loss: 166.20006079253142  F-norm: 101.90530066484614\n",
      "beta: 2  epoch: 29000  loss: 166.20006079253122  F-norm: 101.90530067432532\n",
      "beta: 2  epoch: 30000  loss: 166.20006079253142  F-norm: 101.90530067299562\n",
      "beta: 2  epoch: 31000  loss: 166.2000607925313  F-norm: 101.90530067259897\n",
      "beta: 2  epoch: 32000  loss: 166.2000607925311  F-norm: 101.90530067359401\n",
      "beta: 2  epoch: 33000  loss: 166.200060793511  F-norm: 101.90548410586327\n",
      "beta: 2  epoch: 34000  loss: 166.2000607929846  F-norm: 101.90517591659095\n",
      "beta: 2  epoch: 35000  loss: 166.20006079253125  F-norm: 101.9052995553997\n",
      "beta: 2  epoch: 36000  loss: 166.20006079253136  F-norm: 101.90530077905247\n",
      "beta: 2  epoch: 37000  loss: 166.20006079253142  F-norm: 101.9053006753077\n",
      "beta: 2  epoch: 38000  loss: 166.20006079253153  F-norm: 101.905300673915\n",
      "beta: 2  epoch: 39000  loss: 166.20006079253125  F-norm: 101.90530067352074\n",
      "beta: 2  epoch: 40000  loss: 166.20006079253133  F-norm: 101.90530185883466\n",
      "beta: 4  epoch: 1000  loss: 166.2000608007013  F-norm: 101.9058303550928\n",
      "tensor([[0.0247, 0.0341, 0.7025, 0.0188, 0.0235, 0.0245, 0.0235, 0.0381, 0.7027,\n",
      "         0.0336, 0.0395, 0.0335, 0.0239, 0.0239, 0.0343, 0.0341, 0.7026, 0.0237,\n",
      "         0.0344, 0.0343, 0.0344, 0.0349, 0.0187, 0.0344, 0.0187, 0.0340, 0.0237,\n",
      "         0.0350, 0.0241, 0.0358, 0.0238, 0.7026, 0.0349, 0.0240, 0.0349, 0.0342,\n",
      "         0.0343, 0.0240, 0.0188, 0.7023],\n",
      "        [0.0243, 0.0358, 0.0351, 0.0358, 0.0359, 0.0243, 0.0361, 0.9897, 0.0352,\n",
      "         0.7052, 0.0417, 0.7057, 0.0361, 0.0368, 0.0242, 0.0365, 0.0353, 0.0243,\n",
      "         0.0360, 0.0243, 0.0243, 0.7053, 0.0361, 0.0242, 0.0360, 0.0246, 0.0361,\n",
      "         0.0359, 0.0243, 0.0246, 0.0361, 0.0352, 0.0358, 0.0360, 0.0242, 0.0366,\n",
      "         0.0360, 0.0242, 0.0360, 0.0354],\n",
      "        [0.7034, 0.0343, 0.0370, 0.0184, 0.0238, 0.7033, 0.0235, 0.0234, 0.0242,\n",
      "         0.0238, 0.0408, 0.0235, 0.0237, 0.0240, 0.0355, 0.0237, 0.0356, 0.0343,\n",
      "         0.0344, 0.0343, 0.0344, 0.6996, 0.0236, 0.0349, 0.0242, 0.0237, 0.0343,\n",
      "         0.0344, 0.7029, 0.7030, 0.0235, 0.0242, 0.0342, 0.0343, 0.0343, 0.0235,\n",
      "         0.0343, 0.0364, 0.0242, 0.0241],\n",
      "        [0.7022, 0.0335, 0.0188, 0.7025, 0.0342, 0.0187, 0.0343, 0.0394, 0.0189,\n",
      "         0.0343, 0.0381, 0.0343, 0.0241, 0.0242, 0.0335, 0.0342, 0.0187, 0.0237,\n",
      "         0.0337, 0.0344, 0.0337, 0.0236, 0.7026, 0.0344, 0.0188, 0.0348, 0.0237,\n",
      "         0.0343, 0.0240, 0.0240, 0.0351, 0.7025, 0.0336, 0.0237, 0.0342, 0.0351,\n",
      "         0.0343, 0.0239, 0.7025, 0.0245],\n",
      "        [0.0344, 0.0186, 0.0337, 0.0343, 0.0342, 0.0344, 0.0241, 0.0234, 0.0343,\n",
      "         0.0235, 0.0383, 0.6994, 0.0239, 0.0331, 0.0336, 0.0329, 0.0237, 0.7030,\n",
      "         0.0244, 0.7030, 0.7030, 0.0235, 0.0237, 0.0359, 0.0337, 0.0337, 0.0243,\n",
      "         0.0188, 0.0351, 0.0338, 0.0244, 0.0342, 0.0188, 0.0187, 0.7029, 0.0350,\n",
      "         0.0244, 0.0338, 0.0337, 0.0351],\n",
      "        [0.0237, 0.0368, 0.0239, 0.0239, 0.0342, 0.0348, 0.0364, 0.0395, 0.0239,\n",
      "         0.0344, 0.0382, 0.0237, 0.0366, 0.0352, 0.0336, 0.0336, 0.7028, 0.7025,\n",
      "         0.0241, 0.0242, 0.0242, 0.0342, 0.7028, 0.0235, 0.0354, 0.0343, 0.7027,\n",
      "         0.0242, 0.0350, 0.0344, 0.0240, 0.0185, 0.0242, 0.7029, 0.0184, 0.0235,\n",
      "         0.0241, 0.0352, 0.0239, 0.0240],\n",
      "        [0.0238, 0.0239, 0.0234, 0.0354, 0.6996, 0.0238, 0.7032, 0.0394, 0.0238,\n",
      "         0.0343, 0.0234, 0.0349, 0.0359, 0.0351, 0.0235, 0.0238, 0.0237, 0.0356,\n",
      "         0.0237, 0.0355, 0.0239, 0.0234, 0.0356, 0.0342, 0.0348, 0.0349, 0.0349,\n",
      "         0.0239, 0.7028, 0.0238, 0.7033, 0.0237, 0.0185, 0.0240, 0.0239, 0.0350,\n",
      "         0.0348, 0.0343, 0.0348, 0.7034],\n",
      "        [0.0342, 0.7025, 0.0341, 0.0235, 0.0342, 0.0235, 0.0244, 0.0394, 0.0235,\n",
      "         0.0343, 0.0382, 0.0239, 0.7028, 0.0345, 0.0336, 0.0336, 0.0357, 0.0244,\n",
      "         0.0187, 0.7024, 0.0188, 0.0342, 0.0358, 0.0237, 0.0235, 0.0343, 0.0243,\n",
      "         0.7026, 0.0351, 0.0345, 0.0241, 0.0340, 0.0188, 0.0244, 0.0186, 0.0237,\n",
      "         0.7025, 0.0345, 0.0342, 0.0350],\n",
      "        [0.0238, 0.0342, 0.0236, 0.0354, 0.0240, 0.0238, 0.0352, 0.0406, 0.0348,\n",
      "         0.0245, 0.0236, 0.0343, 0.0352, 0.7033, 0.0187, 0.6996, 0.0342, 0.0338,\n",
      "         0.0237, 0.0337, 0.0337, 0.0237, 0.0351, 0.0187, 0.0240, 0.7023, 0.0237,\n",
      "         0.0337, 0.0238, 0.7028, 0.0344, 0.0347, 0.0336, 0.0337, 0.0329, 0.7031,\n",
      "         0.0237, 0.0187, 0.0240, 0.0351],\n",
      "        [0.0344, 0.0184, 0.0350, 0.0342, 0.0349, 0.0343, 0.0236, 0.0392, 0.0343,\n",
      "         0.0237, 0.0408, 0.0356, 0.0237, 0.0240, 0.0239, 0.0239, 0.0235, 0.0241,\n",
      "         0.7030, 0.0242, 0.0243, 0.0342, 0.0235, 0.7022, 0.0350, 0.0185, 0.7029,\n",
      "         0.0243, 0.0343, 0.0238, 0.0356, 0.0342, 0.0242, 0.0241, 0.0370, 0.7023,\n",
      "         0.7029, 0.0240, 0.0351, 0.0343],\n",
      "        [0.0337, 0.7025, 0.0337, 0.0336, 0.0237, 0.0344, 0.7022, 0.0393, 0.0343,\n",
      "         0.0343, 0.0394, 0.0239, 0.0242, 0.0338, 0.0343, 0.0343, 0.0358, 0.0244,\n",
      "         0.7025, 0.0188, 0.7024, 0.0342, 0.0350, 0.0237, 0.0337, 0.0342, 0.0243,\n",
      "         0.0189, 0.0237, 0.0346, 0.0187, 0.0336, 0.7026, 0.0247, 0.0188, 0.0237,\n",
      "         0.0187, 0.0339, 0.0330, 0.0237],\n",
      "        [0.0361, 0.0352, 0.0369, 0.0344, 0.7055, 0.0361, 0.0243, 0.0416, 0.0353,\n",
      "         0.0244, 0.9898, 0.0352, 0.0346, 0.0247, 0.7051, 0.7053, 0.0353, 0.0347,\n",
      "         0.0369, 0.0346, 0.0354, 0.0367, 0.0345, 0.0248, 0.0360, 0.0189, 0.0362,\n",
      "         0.0354, 0.0246, 0.0248, 0.0243, 0.0352, 0.0359, 0.0354, 0.0354, 0.0247,\n",
      "         0.0361, 0.0248, 0.0360, 0.0243],\n",
      "        [0.0245, 0.0337, 0.7027, 0.0187, 0.0349, 0.0245, 0.0336, 0.0393, 0.0187,\n",
      "         0.0237, 0.0408, 0.0336, 0.0239, 0.7023, 0.0239, 0.0239, 0.0242, 0.0344,\n",
      "         0.0345, 0.0338, 0.0332, 0.0356, 0.0241, 0.0240, 0.7027, 0.0185, 0.0359,\n",
      "         0.0338, 0.0358, 0.0243, 0.0337, 0.0187, 0.0331, 0.0344, 0.0331, 0.0239,\n",
      "         0.0351, 0.7021, 0.7028, 0.0239],\n",
      "        [0.0344, 0.0188, 0.0344, 0.0342, 0.0237, 0.0344, 0.0187, 0.0394, 0.0350,\n",
      "         0.0336, 0.0396, 0.0241, 0.0239, 0.0331, 0.0337, 0.0337, 0.0240, 0.0187,\n",
      "         0.0247, 0.0188, 0.0189, 0.0343, 0.0236, 0.0351, 0.0336, 0.0330, 0.0243,\n",
      "         0.7027, 0.0237, 0.0338, 0.7022, 0.0349, 0.7026, 0.7027, 0.7022, 0.0351,\n",
      "         0.0245, 0.0332, 0.0337, 0.0240],\n",
      "        [0.0187, 0.0235, 0.0187, 0.7025, 0.0342, 0.7022, 0.0351, 0.0394, 0.7026,\n",
      "         0.0343, 0.0381, 0.0343, 0.7028, 0.0242, 0.0335, 0.0342, 0.0241, 0.0350,\n",
      "         0.0342, 0.0235, 0.0343, 0.0237, 0.0244, 0.0343, 0.7025, 0.0349, 0.0350,\n",
      "         0.0235, 0.0240, 0.0240, 0.0350, 0.0188, 0.0341, 0.0350, 0.0341, 0.0350,\n",
      "         0.0235, 0.0239, 0.0188, 0.0242],\n",
      "        [0.0350, 0.0341, 0.0237, 0.0340, 0.0237, 0.0350, 0.0343, 0.0234, 0.0341,\n",
      "         0.6999, 0.0236, 0.0235, 0.0344, 0.0187, 0.6999, 0.0187, 0.0344, 0.0344,\n",
      "         0.0237, 0.0344, 0.0344, 0.0237, 0.0343, 0.7034, 0.0236, 0.7028, 0.0237,\n",
      "         0.0337, 0.0350, 0.0245, 0.0336, 0.0341, 0.0336, 0.0337, 0.0336, 0.0187,\n",
      "         0.0237, 0.7035, 0.0236, 0.0344]], dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "beta: 4  epoch: 2000  loss: 166.200060793305  F-norm: 101.9054637022709\n",
      "beta: 4  epoch: 3000  loss: 166.20006079255535  F-norm: 101.90527192755057\n",
      "beta: 4  epoch: 4000  loss: 166.2000607925316  F-norm: 101.90530434790543\n",
      "beta: 4  epoch: 5000  loss: 166.20006079253596  F-norm: 101.9052877404758\n",
      "beta: 4  epoch: 6000  loss: 166.2000607925359  F-norm: 101.90528814422203\n",
      "beta: 4  epoch: 7000  loss: 166.20006079253173  F-norm: 101.90529733835113\n",
      "beta: 4  epoch: 8000  loss: 166.20006079253176  F-norm: 101.90530425832293\n",
      "beta: 4  epoch: 9000  loss: 166.20006079253125  F-norm: 101.90530058128363\n",
      "beta: 4  epoch: 10000  loss: 166.2000607925313  F-norm: 101.90530067046137\n",
      "beta: 4  epoch: 11000  loss: 166.2000607925313  F-norm: 101.9053006736902\n",
      "beta: 4  epoch: 12000  loss: 166.20006079253173  F-norm: 101.90529682638524\n",
      "beta: 4  epoch: 13000  loss: 166.20006079528846  F-norm: 101.9049929573977\n",
      "beta: 4  epoch: 14000  loss: 166.20006079253227  F-norm: 101.90529483906954\n",
      "beta: 4  epoch: 15000  loss: 166.20006079253136  F-norm: 101.9053010728436\n",
      "beta: 4  epoch: 16000  loss: 166.20006079253122  F-norm: 101.90530079696893\n",
      "beta: 4  epoch: 17000  loss: 166.2000607925312  F-norm: 101.90530066452497\n",
      "beta: 4  epoch: 18000  loss: 166.2000607925312  F-norm: 101.90530067654953\n",
      "beta: 4  epoch: 19000  loss: 166.20006079253147  F-norm: 101.90530067372025\n",
      "beta: 4  epoch: 20000  loss: 166.20006079253145  F-norm: 101.90530067241646\n",
      "beta: 4  epoch: 21000  loss: 166.2000607925312  F-norm: 101.90530067367948\n",
      "beta: 4  epoch: 22000  loss: 166.20006079253133  F-norm: 101.90530067349216\n",
      "beta: 4  epoch: 23000  loss: 166.2000607925314  F-norm: 101.9053009541361\n",
      "beta: 4  epoch: 24000  loss: 166.20006082327896  F-norm: 101.90427306475532\n",
      "beta: 4  epoch: 25000  loss: 166.20006079253673  F-norm: 101.9052872198544\n",
      "beta: 4  epoch: 26000  loss: 166.20006079253153  F-norm: 101.90530036375095\n",
      "beta: 4  epoch: 27000  loss: 166.2000607925313  F-norm: 101.90530067441841\n",
      "beta: 4  epoch: 28000  loss: 166.20006079253127  F-norm: 101.9053007116305\n",
      "beta: 4  epoch: 29000  loss: 166.20006079549182  F-norm: 101.9056195872612\n",
      "beta: 4  epoch: 30000  loss: 166.20006083340047  F-norm: 101.90411599791094\n",
      "beta: 4  epoch: 31000  loss: 166.20006079342505  F-norm: 101.90547586372452\n",
      "beta: 4  epoch: 32000  loss: 166.20006079253318  F-norm: 101.90530890361246\n",
      "beta: 4  epoch: 33000  loss: 166.20006079253147  F-norm: 101.9053005507288\n",
      "beta: 4  epoch: 34000  loss: 166.20006079253125  F-norm: 101.90530067275057\n",
      "beta: 4  epoch: 35000  loss: 166.20006079253125  F-norm: 101.9053006737781\n",
      "beta: 4  epoch: 36000  loss: 166.20006079253127  F-norm: 101.90530067365624\n",
      "beta: 4  epoch: 37000  loss: 166.2000607925314  F-norm: 101.90530067382713\n",
      "beta: 4  epoch: 38000  loss: 166.2000614597243  F-norm: 101.91008788343647\n",
      "beta: 4  epoch: 39000  loss: 166.2000608013399  F-norm: 101.90585068843303\n",
      "beta: 4  epoch: 40000  loss: 166.20006079276624  F-norm: 101.90521087052994\n",
      "beta: 8  epoch: 1000  loss: 166.2000607926671  F-norm: 101.90523237675733\n",
      "tensor([[0.0247, 0.0341, 0.7025, 0.0188, 0.0235, 0.0245, 0.0235, 0.0381, 0.7027,\n",
      "         0.0336, 0.0395, 0.0335, 0.0239, 0.0239, 0.0343, 0.0341, 0.7026, 0.0237,\n",
      "         0.0344, 0.0343, 0.0344, 0.0349, 0.0187, 0.0344, 0.0187, 0.0340, 0.0237,\n",
      "         0.0350, 0.0241, 0.0358, 0.0238, 0.7026, 0.0349, 0.0240, 0.0349, 0.0342,\n",
      "         0.0343, 0.0240, 0.0188, 0.7023],\n",
      "        [0.0243, 0.0358, 0.0351, 0.0358, 0.0359, 0.0243, 0.0361, 0.9897, 0.0352,\n",
      "         0.7052, 0.0417, 0.7057, 0.0361, 0.0368, 0.0242, 0.0365, 0.0353, 0.0243,\n",
      "         0.0360, 0.0243, 0.0243, 0.7053, 0.0361, 0.0242, 0.0360, 0.0246, 0.0361,\n",
      "         0.0359, 0.0243, 0.0246, 0.0361, 0.0352, 0.0358, 0.0360, 0.0242, 0.0366,\n",
      "         0.0360, 0.0243, 0.0360, 0.0354],\n",
      "        [0.7034, 0.0343, 0.0370, 0.0184, 0.0238, 0.7033, 0.0235, 0.0234, 0.0242,\n",
      "         0.0238, 0.0408, 0.0235, 0.0237, 0.0240, 0.0355, 0.0237, 0.0356, 0.0343,\n",
      "         0.0344, 0.0343, 0.0344, 0.6996, 0.0236, 0.0349, 0.0242, 0.0237, 0.0343,\n",
      "         0.0344, 0.7029, 0.7030, 0.0235, 0.0242, 0.0342, 0.0343, 0.0343, 0.0235,\n",
      "         0.0343, 0.0364, 0.0242, 0.0241],\n",
      "        [0.7022, 0.0335, 0.0188, 0.7025, 0.0342, 0.0187, 0.0343, 0.0394, 0.0189,\n",
      "         0.0343, 0.0381, 0.0343, 0.0241, 0.0242, 0.0335, 0.0342, 0.0187, 0.0237,\n",
      "         0.0337, 0.0344, 0.0337, 0.0236, 0.7026, 0.0344, 0.0188, 0.0348, 0.0237,\n",
      "         0.0343, 0.0240, 0.0240, 0.0351, 0.7025, 0.0336, 0.0237, 0.0342, 0.0351,\n",
      "         0.0343, 0.0239, 0.7025, 0.0245],\n",
      "        [0.0344, 0.0186, 0.0337, 0.0343, 0.0342, 0.0344, 0.0241, 0.0234, 0.0343,\n",
      "         0.0235, 0.0383, 0.6994, 0.0239, 0.0331, 0.0336, 0.0329, 0.0237, 0.7030,\n",
      "         0.0244, 0.7030, 0.7030, 0.0235, 0.0237, 0.0359, 0.0337, 0.0337, 0.0243,\n",
      "         0.0188, 0.0351, 0.0338, 0.0244, 0.0342, 0.0188, 0.0187, 0.7029, 0.0350,\n",
      "         0.0244, 0.0338, 0.0337, 0.0351],\n",
      "        [0.0237, 0.0368, 0.0239, 0.0239, 0.0342, 0.0348, 0.0364, 0.0395, 0.0239,\n",
      "         0.0344, 0.0382, 0.0237, 0.0366, 0.0352, 0.0336, 0.0336, 0.7028, 0.7025,\n",
      "         0.0241, 0.0242, 0.0242, 0.0342, 0.7028, 0.0235, 0.0354, 0.0343, 0.7027,\n",
      "         0.0242, 0.0350, 0.0344, 0.0240, 0.0185, 0.0242, 0.7029, 0.0184, 0.0235,\n",
      "         0.0241, 0.0352, 0.0239, 0.0240],\n",
      "        [0.0238, 0.0239, 0.0234, 0.0354, 0.6996, 0.0238, 0.7032, 0.0394, 0.0238,\n",
      "         0.0343, 0.0234, 0.0349, 0.0359, 0.0351, 0.0235, 0.0238, 0.0237, 0.0356,\n",
      "         0.0237, 0.0355, 0.0239, 0.0234, 0.0356, 0.0342, 0.0348, 0.0349, 0.0349,\n",
      "         0.0239, 0.7028, 0.0238, 0.7033, 0.0237, 0.0185, 0.0240, 0.0239, 0.0350,\n",
      "         0.0348, 0.0343, 0.0348, 0.7034],\n",
      "        [0.0342, 0.7025, 0.0341, 0.0235, 0.0342, 0.0235, 0.0244, 0.0394, 0.0235,\n",
      "         0.0343, 0.0382, 0.0239, 0.7028, 0.0345, 0.0336, 0.0336, 0.0357, 0.0244,\n",
      "         0.0187, 0.7024, 0.0188, 0.0342, 0.0358, 0.0237, 0.0235, 0.0343, 0.0243,\n",
      "         0.7026, 0.0351, 0.0345, 0.0241, 0.0340, 0.0188, 0.0244, 0.0186, 0.0237,\n",
      "         0.7025, 0.0345, 0.0342, 0.0350],\n",
      "        [0.0238, 0.0342, 0.0236, 0.0354, 0.0240, 0.0238, 0.0352, 0.0406, 0.0348,\n",
      "         0.0245, 0.0236, 0.0343, 0.0352, 0.7033, 0.0187, 0.6996, 0.0342, 0.0338,\n",
      "         0.0237, 0.0337, 0.0337, 0.0237, 0.0351, 0.0187, 0.0240, 0.7023, 0.0237,\n",
      "         0.0337, 0.0238, 0.7028, 0.0344, 0.0347, 0.0336, 0.0337, 0.0329, 0.7031,\n",
      "         0.0237, 0.0187, 0.0240, 0.0351],\n",
      "        [0.0344, 0.0184, 0.0350, 0.0342, 0.0349, 0.0343, 0.0236, 0.0392, 0.0343,\n",
      "         0.0237, 0.0408, 0.0356, 0.0237, 0.0240, 0.0240, 0.0239, 0.0235, 0.0241,\n",
      "         0.7030, 0.0242, 0.0243, 0.0342, 0.0235, 0.7022, 0.0350, 0.0185, 0.7029,\n",
      "         0.0243, 0.0343, 0.0238, 0.0356, 0.0342, 0.0242, 0.0241, 0.0370, 0.7023,\n",
      "         0.7029, 0.0240, 0.0351, 0.0343],\n",
      "        [0.0337, 0.7025, 0.0337, 0.0336, 0.0237, 0.0344, 0.7022, 0.0393, 0.0343,\n",
      "         0.0343, 0.0394, 0.0239, 0.0242, 0.0338, 0.0343, 0.0343, 0.0358, 0.0244,\n",
      "         0.7025, 0.0188, 0.7024, 0.0342, 0.0350, 0.0237, 0.0337, 0.0342, 0.0243,\n",
      "         0.0189, 0.0237, 0.0346, 0.0187, 0.0336, 0.7026, 0.0247, 0.0188, 0.0237,\n",
      "         0.0187, 0.0339, 0.0330, 0.0237],\n",
      "        [0.0361, 0.0352, 0.0369, 0.0344, 0.7055, 0.0361, 0.0243, 0.0416, 0.0353,\n",
      "         0.0244, 0.9898, 0.0352, 0.0346, 0.0247, 0.7051, 0.7053, 0.0353, 0.0347,\n",
      "         0.0369, 0.0346, 0.0354, 0.0367, 0.0345, 0.0248, 0.0360, 0.0189, 0.0362,\n",
      "         0.0354, 0.0246, 0.0248, 0.0243, 0.0352, 0.0359, 0.0354, 0.0354, 0.0247,\n",
      "         0.0361, 0.0248, 0.0360, 0.0243],\n",
      "        [0.0245, 0.0337, 0.7027, 0.0187, 0.0349, 0.0245, 0.0336, 0.0393, 0.0187,\n",
      "         0.0237, 0.0408, 0.0336, 0.0239, 0.7023, 0.0239, 0.0239, 0.0242, 0.0344,\n",
      "         0.0345, 0.0338, 0.0332, 0.0356, 0.0241, 0.0240, 0.7027, 0.0185, 0.0359,\n",
      "         0.0338, 0.0358, 0.0243, 0.0337, 0.0187, 0.0331, 0.0344, 0.0331, 0.0239,\n",
      "         0.0351, 0.7021, 0.7028, 0.0239],\n",
      "        [0.0344, 0.0188, 0.0344, 0.0342, 0.0237, 0.0344, 0.0187, 0.0394, 0.0350,\n",
      "         0.0336, 0.0396, 0.0241, 0.0239, 0.0331, 0.0337, 0.0337, 0.0240, 0.0187,\n",
      "         0.0247, 0.0188, 0.0189, 0.0343, 0.0236, 0.0351, 0.0336, 0.0330, 0.0243,\n",
      "         0.7027, 0.0237, 0.0338, 0.7022, 0.0349, 0.7026, 0.7027, 0.7022, 0.0351,\n",
      "         0.0245, 0.0332, 0.0337, 0.0240],\n",
      "        [0.0187, 0.0235, 0.0187, 0.7025, 0.0342, 0.7022, 0.0351, 0.0394, 0.7026,\n",
      "         0.0343, 0.0381, 0.0343, 0.7028, 0.0242, 0.0335, 0.0342, 0.0241, 0.0350,\n",
      "         0.0342, 0.0235, 0.0343, 0.0237, 0.0244, 0.0343, 0.7025, 0.0349, 0.0350,\n",
      "         0.0235, 0.0240, 0.0240, 0.0351, 0.0188, 0.0341, 0.0350, 0.0341, 0.0350,\n",
      "         0.0235, 0.0239, 0.0188, 0.0242],\n",
      "        [0.0350, 0.0341, 0.0237, 0.0340, 0.0237, 0.0350, 0.0343, 0.0234, 0.0341,\n",
      "         0.6999, 0.0236, 0.0235, 0.0344, 0.0187, 0.6999, 0.0187, 0.0344, 0.0344,\n",
      "         0.0237, 0.0344, 0.0344, 0.0237, 0.0343, 0.7034, 0.0236, 0.7028, 0.0237,\n",
      "         0.0337, 0.0350, 0.0245, 0.0336, 0.0341, 0.0336, 0.0337, 0.0336, 0.0187,\n",
      "         0.0237, 0.7035, 0.0237, 0.0344]], dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<DivBackward0>)\n",
      "beta: 8  epoch: 2000  loss: 166.20006079253153  F-norm: 101.90529709953334\n",
      "beta: 8  epoch: 3000  loss: 166.20006079253156  F-norm: 101.90529706994099\n",
      "beta: 8  epoch: 4000  loss: 166.20006079253125  F-norm: 101.90530035764837\n",
      "beta: 8  epoch: 5000  loss: 166.20006079253142  F-norm: 101.90530062658578\n",
      "beta: 8  epoch: 6000  loss: 166.20006079253153  F-norm: 101.90530063916731\n",
      "beta: 8  epoch: 7000  loss: 166.20006079253116  F-norm: 101.90530067486112\n",
      "beta: 8  epoch: 8000  loss: 166.20006079253125  F-norm: 101.90530065436786\n",
      "beta: 8  epoch: 9000  loss: 166.20006079253125  F-norm: 101.90530067994409\n",
      "beta: 8  epoch: 10000  loss: 166.20006079253108  F-norm: 101.90530067313014\n",
      "beta: 8  epoch: 11000  loss: 166.20006079253127  F-norm: 101.90530067363923\n",
      "beta: 8  epoch: 12000  loss: 166.20006079596467  F-norm: 101.90495729585027\n",
      "beta: 8  epoch: 13000  loss: 166.20006079262106  F-norm: 101.90524513918233\n",
      "beta: 8  epoch: 14000  loss: 166.20006079253136  F-norm: 101.90530076038702\n",
      "beta: 8  epoch: 15000  loss: 166.20006079253125  F-norm: 101.90530067657757\n",
      "beta: 8  epoch: 16000  loss: 166.20006079253102  F-norm: 101.9053006736434\n",
      "beta: 8  epoch: 17000  loss: 166.2000608274829  F-norm: 101.90420509105623\n",
      "beta: 8  epoch: 18000  loss: 166.2000607925484  F-norm: 101.9053250838352\n",
      "beta: 8  epoch: 19000  loss: 166.2000608139744  F-norm: 101.90444252114186\n",
      "beta: 8  epoch: 20000  loss: 166.2000607929621  F-norm: 101.90542230321923\n",
      "beta: 8  epoch: 21000  loss: 166.20006079254455  F-norm: 101.9052794381414\n",
      "beta: 8  epoch: 22000  loss: 166.2000607925322  F-norm: 101.90530592620206\n",
      "beta: 8  epoch: 23000  loss: 166.20006079253102  F-norm: 101.90530116327594\n",
      "beta: 8  epoch: 24000  loss: 166.2000607925312  F-norm: 101.90530069897686\n",
      "beta: 8  epoch: 25000  loss: 166.20006079253116  F-norm: 101.90530067075294\n",
      "beta: 8  epoch: 26000  loss: 166.20006079253136  F-norm: 101.90530067369059\n",
      "beta: 8  epoch: 27000  loss: 166.20006079253113  F-norm: 101.90530067408334\n",
      "beta: 8  epoch: 28000  loss: 166.20006079253105  F-norm: 101.90530048016439\n",
      "beta: 8  epoch: 29000  loss: 166.20006079259073  F-norm: 101.90525553011175\n",
      "beta: 8  epoch: 30000  loss: 166.20006081819722  F-norm: 101.90623951750632\n",
      "beta: 8  epoch: 31000  loss: 166.20006079305466  F-norm: 101.90516661223558\n",
      "beta: 8  epoch: 32000  loss: 166.20006079253875  F-norm: 101.90528459157703\n",
      "beta: 8  epoch: 33000  loss: 166.20006079253113  F-norm: 101.90530050805792\n",
      "beta: 8  epoch: 34000  loss: 166.2000607925313  F-norm: 101.90530067725902\n",
      "beta: 8  epoch: 35000  loss: 166.20006079253113  F-norm: 101.90530067415938\n",
      "beta: 8  epoch: 36000  loss: 166.20006079253116  F-norm: 101.90530067367887\n",
      "beta: 8  epoch: 37000  loss: 166.2000607925312  F-norm: 101.90530067432668\n",
      "beta: 8  epoch: 38000  loss: 166.20006079253125  F-norm: 101.9053007262\n",
      "beta: 8  epoch: 39000  loss: 166.20006079253116  F-norm: 101.90530067352834\n",
      "beta: 8  epoch: 40000  loss: 166.20006079253113  F-norm: 101.90530067362084\n",
      "beta: 16  epoch: 1000  loss: 166.20006079253133  F-norm: 101.90530065162997\n",
      "tensor([[0.0247, 0.0341, 0.7025, 0.0188, 0.0235, 0.0245, 0.0235, 0.0381, 0.7027,\n",
      "         0.0336, 0.0395, 0.0335, 0.0239, 0.0239, 0.0343, 0.0341, 0.7026, 0.0237,\n",
      "         0.0344, 0.0343, 0.0344, 0.0349, 0.0187, 0.0344, 0.0187, 0.0340, 0.0237,\n",
      "         0.0350, 0.0241, 0.0358, 0.0238, 0.7026, 0.0349, 0.0240, 0.0349, 0.0342,\n",
      "         0.0343, 0.0240, 0.0188, 0.7023],\n",
      "        [0.0243, 0.0358, 0.0351, 0.0358, 0.0359, 0.0243, 0.0361, 0.9897, 0.0352,\n",
      "         0.7052, 0.0417, 0.7057, 0.0361, 0.0368, 0.0242, 0.0365, 0.0353, 0.0243,\n",
      "         0.0360, 0.0243, 0.0243, 0.7053, 0.0361, 0.0242, 0.0360, 0.0246, 0.0361,\n",
      "         0.0359, 0.0243, 0.0246, 0.0361, 0.0352, 0.0358, 0.0360, 0.0242, 0.0366,\n",
      "         0.0360, 0.0243, 0.0360, 0.0354],\n",
      "        [0.7034, 0.0343, 0.0370, 0.0184, 0.0238, 0.7033, 0.0235, 0.0234, 0.0242,\n",
      "         0.0238, 0.0408, 0.0235, 0.0237, 0.0240, 0.0355, 0.0237, 0.0356, 0.0343,\n",
      "         0.0344, 0.0343, 0.0344, 0.6996, 0.0236, 0.0349, 0.0242, 0.0237, 0.0343,\n",
      "         0.0344, 0.7029, 0.7030, 0.0235, 0.0242, 0.0342, 0.0343, 0.0343, 0.0235,\n",
      "         0.0343, 0.0364, 0.0242, 0.0241],\n",
      "        [0.7022, 0.0335, 0.0188, 0.7025, 0.0342, 0.0187, 0.0343, 0.0394, 0.0189,\n",
      "         0.0343, 0.0381, 0.0343, 0.0241, 0.0242, 0.0335, 0.0342, 0.0187, 0.0237,\n",
      "         0.0337, 0.0344, 0.0337, 0.0236, 0.7026, 0.0344, 0.0188, 0.0348, 0.0237,\n",
      "         0.0343, 0.0240, 0.0240, 0.0351, 0.7025, 0.0336, 0.0237, 0.0342, 0.0351,\n",
      "         0.0343, 0.0239, 0.7025, 0.0245],\n",
      "        [0.0344, 0.0186, 0.0337, 0.0343, 0.0342, 0.0344, 0.0241, 0.0234, 0.0343,\n",
      "         0.0235, 0.0383, 0.6994, 0.0239, 0.0331, 0.0336, 0.0329, 0.0237, 0.7030,\n",
      "         0.0244, 0.7030, 0.7030, 0.0235, 0.0237, 0.0359, 0.0337, 0.0337, 0.0243,\n",
      "         0.0188, 0.0351, 0.0338, 0.0244, 0.0342, 0.0188, 0.0187, 0.7029, 0.0350,\n",
      "         0.0244, 0.0338, 0.0337, 0.0351],\n",
      "        [0.0237, 0.0368, 0.0239, 0.0239, 0.0342, 0.0348, 0.0364, 0.0395, 0.0239,\n",
      "         0.0344, 0.0382, 0.0237, 0.0366, 0.0352, 0.0336, 0.0336, 0.7028, 0.7025,\n",
      "         0.0241, 0.0242, 0.0242, 0.0342, 0.7028, 0.0235, 0.0354, 0.0343, 0.7027,\n",
      "         0.0242, 0.0350, 0.0344, 0.0240, 0.0185, 0.0242, 0.7029, 0.0184, 0.0235,\n",
      "         0.0241, 0.0352, 0.0239, 0.0240],\n",
      "        [0.0238, 0.0239, 0.0234, 0.0354, 0.6996, 0.0238, 0.7032, 0.0394, 0.0238,\n",
      "         0.0343, 0.0234, 0.0349, 0.0359, 0.0351, 0.0235, 0.0238, 0.0237, 0.0356,\n",
      "         0.0237, 0.0355, 0.0239, 0.0234, 0.0356, 0.0342, 0.0348, 0.0349, 0.0349,\n",
      "         0.0239, 0.7028, 0.0238, 0.7033, 0.0237, 0.0185, 0.0240, 0.0239, 0.0350,\n",
      "         0.0348, 0.0343, 0.0348, 0.7034],\n",
      "        [0.0342, 0.7025, 0.0341, 0.0235, 0.0342, 0.0235, 0.0244, 0.0394, 0.0235,\n",
      "         0.0343, 0.0382, 0.0239, 0.7028, 0.0345, 0.0336, 0.0336, 0.0357, 0.0244,\n",
      "         0.0187, 0.7024, 0.0188, 0.0342, 0.0358, 0.0237, 0.0235, 0.0343, 0.0243,\n",
      "         0.7026, 0.0351, 0.0345, 0.0241, 0.0340, 0.0188, 0.0244, 0.0186, 0.0237,\n",
      "         0.7025, 0.0345, 0.0342, 0.0350],\n",
      "        [0.0238, 0.0342, 0.0236, 0.0354, 0.0240, 0.0238, 0.0352, 0.0406, 0.0348,\n",
      "         0.0245, 0.0236, 0.0343, 0.0352, 0.7033, 0.0187, 0.6996, 0.0342, 0.0338,\n",
      "         0.0237, 0.0337, 0.0337, 0.0237, 0.0351, 0.0187, 0.0240, 0.7023, 0.0237,\n",
      "         0.0337, 0.0238, 0.7028, 0.0344, 0.0347, 0.0336, 0.0337, 0.0329, 0.7031,\n",
      "         0.0237, 0.0187, 0.0240, 0.0351],\n",
      "        [0.0344, 0.0184, 0.0350, 0.0342, 0.0349, 0.0343, 0.0236, 0.0392, 0.0343,\n",
      "         0.0237, 0.0408, 0.0356, 0.0237, 0.0240, 0.0240, 0.0239, 0.0235, 0.0241,\n",
      "         0.7030, 0.0242, 0.0243, 0.0342, 0.0235, 0.7022, 0.0350, 0.0185, 0.7029,\n",
      "         0.0243, 0.0343, 0.0238, 0.0356, 0.0342, 0.0242, 0.0241, 0.0370, 0.7023,\n",
      "         0.7029, 0.0240, 0.0351, 0.0343],\n",
      "        [0.0337, 0.7025, 0.0337, 0.0336, 0.0237, 0.0344, 0.7022, 0.0393, 0.0343,\n",
      "         0.0343, 0.0394, 0.0239, 0.0242, 0.0338, 0.0343, 0.0343, 0.0358, 0.0244,\n",
      "         0.7025, 0.0188, 0.7024, 0.0342, 0.0350, 0.0237, 0.0337, 0.0342, 0.0243,\n",
      "         0.0189, 0.0237, 0.0346, 0.0187, 0.0336, 0.7026, 0.0247, 0.0188, 0.0237,\n",
      "         0.0187, 0.0339, 0.0330, 0.0237],\n",
      "        [0.0361, 0.0352, 0.0369, 0.0344, 0.7055, 0.0361, 0.0243, 0.0416, 0.0353,\n",
      "         0.0244, 0.9898, 0.0352, 0.0346, 0.0247, 0.7051, 0.7053, 0.0353, 0.0347,\n",
      "         0.0369, 0.0346, 0.0354, 0.0367, 0.0345, 0.0248, 0.0360, 0.0189, 0.0362,\n",
      "         0.0354, 0.0246, 0.0248, 0.0243, 0.0352, 0.0359, 0.0354, 0.0354, 0.0247,\n",
      "         0.0361, 0.0248, 0.0360, 0.0243],\n",
      "        [0.0245, 0.0337, 0.7027, 0.0187, 0.0349, 0.0245, 0.0336, 0.0393, 0.0187,\n",
      "         0.0237, 0.0408, 0.0336, 0.0239, 0.7023, 0.0239, 0.0239, 0.0242, 0.0344,\n",
      "         0.0345, 0.0338, 0.0332, 0.0356, 0.0241, 0.0240, 0.7027, 0.0185, 0.0359,\n",
      "         0.0338, 0.0358, 0.0243, 0.0337, 0.0187, 0.0331, 0.0344, 0.0331, 0.0239,\n",
      "         0.0351, 0.7021, 0.7028, 0.0239],\n",
      "        [0.0344, 0.0188, 0.0344, 0.0342, 0.0237, 0.0344, 0.0187, 0.0394, 0.0350,\n",
      "         0.0336, 0.0396, 0.0241, 0.0239, 0.0331, 0.0337, 0.0337, 0.0240, 0.0187,\n",
      "         0.0247, 0.0188, 0.0189, 0.0343, 0.0236, 0.0351, 0.0336, 0.0330, 0.0243,\n",
      "         0.7027, 0.0237, 0.0338, 0.7022, 0.0349, 0.7026, 0.7027, 0.7022, 0.0351,\n",
      "         0.0245, 0.0332, 0.0337, 0.0240],\n",
      "        [0.0187, 0.0235, 0.0187, 0.7025, 0.0342, 0.7022, 0.0351, 0.0394, 0.7026,\n",
      "         0.0343, 0.0381, 0.0343, 0.7028, 0.0242, 0.0335, 0.0342, 0.0241, 0.0350,\n",
      "         0.0342, 0.0235, 0.0343, 0.0237, 0.0244, 0.0343, 0.7025, 0.0349, 0.0350,\n",
      "         0.0235, 0.0240, 0.0240, 0.0351, 0.0188, 0.0341, 0.0350, 0.0341, 0.0350,\n",
      "         0.0235, 0.0239, 0.0188, 0.0242],\n",
      "        [0.0350, 0.0341, 0.0237, 0.0340, 0.0237, 0.0350, 0.0343, 0.0234, 0.0341,\n",
      "         0.6999, 0.0236, 0.0235, 0.0344, 0.0187, 0.6999, 0.0187, 0.0344, 0.0344,\n",
      "         0.0237, 0.0344, 0.0344, 0.0237, 0.0343, 0.7034, 0.0236, 0.7028, 0.0237,\n",
      "         0.0337, 0.0350, 0.0245, 0.0336, 0.0341, 0.0336, 0.0337, 0.0336, 0.0187,\n",
      "         0.0237, 0.7035, 0.0237, 0.0344]], dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<DivBackward0>)\n",
      "beta: 16  epoch: 2000  loss: 166.20006079272974  F-norm: 101.90538326297006\n",
      "beta: 16  epoch: 3000  loss: 166.2000608067017  F-norm: 101.90460305425925\n",
      "beta: 16  epoch: 4000  loss: 166.200060792763  F-norm: 101.9052114522536\n",
      "beta: 16  epoch: 5000  loss: 166.20006079253292  F-norm: 101.90529335668668\n",
      "beta: 16  epoch: 6000  loss: 166.20006079253125  F-norm: 101.90530059648532\n",
      "beta: 16  epoch: 7000  loss: 166.20006079253108  F-norm: 101.90530053343151\n",
      "beta: 16  epoch: 8000  loss: 166.2000607925313  F-norm: 101.90530065368803\n",
      "beta: 16  epoch: 9000  loss: 166.20006079253153  F-norm: 101.90530069579164\n",
      "beta: 16  epoch: 10000  loss: 166.2000607925312  F-norm: 101.90530067426664\n",
      "beta: 16  epoch: 11000  loss: 166.2000607925313  F-norm: 101.90530067353505\n",
      "beta: 16  epoch: 12000  loss: 166.20006079253147  F-norm: 101.90530067369475\n",
      "beta: 16  epoch: 13000  loss: 166.20006079253122  F-norm: 101.90530067327482\n",
      "beta: 16  epoch: 14000  loss: 166.20006079253108  F-norm: 101.90530067313047\n",
      "beta: 16  epoch: 15000  loss: 166.2000607925312  F-norm: 101.90530067310841\n",
      "beta: 16  epoch: 16000  loss: 166.2000607925311  F-norm: 101.90530067364386\n",
      "beta: 16  epoch: 17000  loss: 166.20006079253142  F-norm: 101.9053006735461\n",
      "beta: 16  epoch: 18000  loss: 166.20006079253147  F-norm: 101.90530067661226\n",
      "beta: 16  epoch: 19000  loss: 166.20006083335767  F-norm: 101.90411660130313\n",
      "beta: 16  epoch: 20000  loss: 166.20006079345563  F-norm: 101.90547886342112\n",
      "beta: 16  epoch: 21000  loss: 166.20006079253176  F-norm: 101.90530447521746\n",
      "beta: 16  epoch: 22000  loss: 166.2000607925312  F-norm: 101.90530077783916\n",
      "beta: 16  epoch: 23000  loss: 166.20006079253113  F-norm: 101.90530136332362\n",
      "beta: 16  epoch: 24000  loss: 166.20006079253127  F-norm: 101.90530025316689\n",
      "beta: 16  epoch: 25000  loss: 166.20006079253244  F-norm: 101.90529398200077\n",
      "beta: 16  epoch: 26000  loss: 166.20006079254154  F-norm: 101.90531947343169\n",
      "beta: 16  epoch: 27000  loss: 166.20006079253156  F-norm: 101.9052982240978\n",
      "beta: 16  epoch: 28000  loss: 166.20006079253136  F-norm: 101.90530039031935\n",
      "beta: 16  epoch: 29000  loss: 166.20006079253142  F-norm: 101.90530064773468\n",
      "beta: 16  epoch: 30000  loss: 166.2000607925314  F-norm: 101.90530067463335\n",
      "beta: 16  epoch: 31000  loss: 166.20006079253116  F-norm: 101.90530067381407\n",
      "beta: 16  epoch: 32000  loss: 166.2000607925313  F-norm: 101.90530067363949\n",
      "beta: 16  epoch: 33000  loss: 166.20006187686477  F-norm: 101.89919893820077\n",
      "beta: 16  epoch: 34000  loss: 166.20006079253204  F-norm: 101.90529613101172\n",
      "beta: 16  epoch: 35000  loss: 166.20006079253142  F-norm: 101.90530033197187\n",
      "beta: 16  epoch: 36000  loss: 166.20006079253127  F-norm: 101.90530067256776\n",
      "beta: 16  epoch: 37000  loss: 166.2000607925312  F-norm: 101.90530067356389\n",
      "beta: 16  epoch: 38000  loss: 166.2000607925313  F-norm: 101.90529873188888\n",
      "beta: 16  epoch: 39000  loss: 166.20006079324307  F-norm: 101.90514428805363\n",
      "beta: 16  epoch: 40000  loss: 166.20006079253181  F-norm: 101.90529686357907\n",
      "beta: 32  epoch: 1000  loss: 166.20006079253136  F-norm: 101.90530065641768\n",
      "tensor([[0.0247, 0.0341, 0.7025, 0.0188, 0.0235, 0.0245, 0.0235, 0.0381, 0.7027,\n",
      "         0.0336, 0.0395, 0.0335, 0.0239, 0.0239, 0.0343, 0.0341, 0.7026, 0.0237,\n",
      "         0.0344, 0.0343, 0.0344, 0.0349, 0.0187, 0.0344, 0.0187, 0.0340, 0.0237,\n",
      "         0.0350, 0.0241, 0.0358, 0.0238, 0.7026, 0.0349, 0.0240, 0.0349, 0.0342,\n",
      "         0.0343, 0.0240, 0.0188, 0.7023],\n",
      "        [0.0243, 0.0358, 0.0351, 0.0358, 0.0359, 0.0243, 0.0361, 0.9897, 0.0352,\n",
      "         0.7052, 0.0417, 0.7057, 0.0361, 0.0368, 0.0242, 0.0365, 0.0353, 0.0243,\n",
      "         0.0360, 0.0243, 0.0243, 0.7053, 0.0361, 0.0242, 0.0360, 0.0246, 0.0361,\n",
      "         0.0359, 0.0243, 0.0246, 0.0361, 0.0352, 0.0358, 0.0360, 0.0242, 0.0366,\n",
      "         0.0360, 0.0243, 0.0360, 0.0354],\n",
      "        [0.7034, 0.0343, 0.0370, 0.0184, 0.0238, 0.7033, 0.0235, 0.0234, 0.0242,\n",
      "         0.0238, 0.0408, 0.0235, 0.0237, 0.0240, 0.0355, 0.0237, 0.0356, 0.0343,\n",
      "         0.0344, 0.0343, 0.0344, 0.6996, 0.0236, 0.0349, 0.0242, 0.0237, 0.0343,\n",
      "         0.0344, 0.7029, 0.7030, 0.0235, 0.0242, 0.0342, 0.0343, 0.0343, 0.0235,\n",
      "         0.0343, 0.0364, 0.0242, 0.0241],\n",
      "        [0.7022, 0.0335, 0.0188, 0.7025, 0.0342, 0.0187, 0.0343, 0.0394, 0.0189,\n",
      "         0.0343, 0.0381, 0.0343, 0.0241, 0.0242, 0.0335, 0.0342, 0.0187, 0.0237,\n",
      "         0.0337, 0.0344, 0.0337, 0.0236, 0.7026, 0.0344, 0.0188, 0.0348, 0.0237,\n",
      "         0.0343, 0.0240, 0.0240, 0.0351, 0.7025, 0.0336, 0.0237, 0.0342, 0.0351,\n",
      "         0.0343, 0.0239, 0.7025, 0.0245],\n",
      "        [0.0344, 0.0186, 0.0337, 0.0343, 0.0342, 0.0344, 0.0241, 0.0234, 0.0343,\n",
      "         0.0235, 0.0383, 0.6994, 0.0239, 0.0331, 0.0336, 0.0329, 0.0237, 0.7030,\n",
      "         0.0244, 0.7030, 0.7030, 0.0235, 0.0237, 0.0359, 0.0337, 0.0337, 0.0243,\n",
      "         0.0188, 0.0351, 0.0338, 0.0244, 0.0342, 0.0188, 0.0187, 0.7029, 0.0350,\n",
      "         0.0244, 0.0338, 0.0337, 0.0351],\n",
      "        [0.0237, 0.0368, 0.0239, 0.0239, 0.0342, 0.0348, 0.0364, 0.0395, 0.0239,\n",
      "         0.0344, 0.0382, 0.0237, 0.0366, 0.0352, 0.0336, 0.0336, 0.7028, 0.7025,\n",
      "         0.0241, 0.0242, 0.0242, 0.0342, 0.7028, 0.0235, 0.0354, 0.0343, 0.7027,\n",
      "         0.0242, 0.0350, 0.0344, 0.0240, 0.0185, 0.0242, 0.7029, 0.0184, 0.0235,\n",
      "         0.0241, 0.0352, 0.0239, 0.0240],\n",
      "        [0.0238, 0.0239, 0.0234, 0.0354, 0.6996, 0.0238, 0.7032, 0.0394, 0.0238,\n",
      "         0.0343, 0.0234, 0.0349, 0.0359, 0.0351, 0.0235, 0.0238, 0.0237, 0.0356,\n",
      "         0.0237, 0.0355, 0.0239, 0.0234, 0.0356, 0.0342, 0.0348, 0.0349, 0.0349,\n",
      "         0.0239, 0.7028, 0.0238, 0.7033, 0.0237, 0.0185, 0.0240, 0.0239, 0.0350,\n",
      "         0.0348, 0.0343, 0.0348, 0.7034],\n",
      "        [0.0342, 0.7025, 0.0341, 0.0235, 0.0342, 0.0235, 0.0244, 0.0394, 0.0235,\n",
      "         0.0343, 0.0382, 0.0239, 0.7028, 0.0345, 0.0336, 0.0336, 0.0357, 0.0244,\n",
      "         0.0187, 0.7024, 0.0188, 0.0342, 0.0358, 0.0237, 0.0235, 0.0343, 0.0243,\n",
      "         0.7026, 0.0351, 0.0345, 0.0241, 0.0340, 0.0188, 0.0244, 0.0186, 0.0237,\n",
      "         0.7025, 0.0345, 0.0342, 0.0350],\n",
      "        [0.0238, 0.0342, 0.0236, 0.0354, 0.0240, 0.0238, 0.0352, 0.0406, 0.0348,\n",
      "         0.0245, 0.0236, 0.0343, 0.0352, 0.7033, 0.0187, 0.6996, 0.0342, 0.0338,\n",
      "         0.0237, 0.0337, 0.0337, 0.0237, 0.0351, 0.0187, 0.0240, 0.7023, 0.0237,\n",
      "         0.0337, 0.0238, 0.7028, 0.0344, 0.0347, 0.0336, 0.0337, 0.0329, 0.7031,\n",
      "         0.0237, 0.0187, 0.0240, 0.0351],\n",
      "        [0.0344, 0.0184, 0.0350, 0.0342, 0.0349, 0.0343, 0.0236, 0.0392, 0.0343,\n",
      "         0.0237, 0.0408, 0.0356, 0.0237, 0.0240, 0.0240, 0.0239, 0.0235, 0.0241,\n",
      "         0.7030, 0.0242, 0.0243, 0.0342, 0.0235, 0.7022, 0.0350, 0.0185, 0.7029,\n",
      "         0.0243, 0.0343, 0.0238, 0.0356, 0.0342, 0.0242, 0.0241, 0.0370, 0.7023,\n",
      "         0.7029, 0.0240, 0.0351, 0.0343],\n",
      "        [0.0337, 0.7025, 0.0337, 0.0336, 0.0237, 0.0344, 0.7022, 0.0393, 0.0343,\n",
      "         0.0343, 0.0394, 0.0239, 0.0242, 0.0338, 0.0343, 0.0343, 0.0358, 0.0244,\n",
      "         0.7025, 0.0188, 0.7024, 0.0342, 0.0350, 0.0237, 0.0337, 0.0342, 0.0243,\n",
      "         0.0189, 0.0237, 0.0346, 0.0187, 0.0336, 0.7026, 0.0247, 0.0188, 0.0237,\n",
      "         0.0187, 0.0339, 0.0330, 0.0237],\n",
      "        [0.0361, 0.0352, 0.0369, 0.0344, 0.7055, 0.0361, 0.0243, 0.0416, 0.0353,\n",
      "         0.0244, 0.9898, 0.0352, 0.0346, 0.0247, 0.7051, 0.7053, 0.0353, 0.0347,\n",
      "         0.0369, 0.0346, 0.0354, 0.0367, 0.0345, 0.0248, 0.0360, 0.0189, 0.0362,\n",
      "         0.0354, 0.0246, 0.0248, 0.0243, 0.0352, 0.0359, 0.0354, 0.0354, 0.0247,\n",
      "         0.0361, 0.0248, 0.0360, 0.0243],\n",
      "        [0.0245, 0.0337, 0.7027, 0.0187, 0.0349, 0.0245, 0.0336, 0.0393, 0.0187,\n",
      "         0.0237, 0.0408, 0.0336, 0.0239, 0.7023, 0.0239, 0.0239, 0.0242, 0.0344,\n",
      "         0.0345, 0.0338, 0.0332, 0.0356, 0.0241, 0.0240, 0.7027, 0.0185, 0.0359,\n",
      "         0.0338, 0.0358, 0.0243, 0.0337, 0.0187, 0.0331, 0.0344, 0.0331, 0.0239,\n",
      "         0.0351, 0.7021, 0.7028, 0.0239],\n",
      "        [0.0344, 0.0188, 0.0344, 0.0342, 0.0237, 0.0344, 0.0187, 0.0394, 0.0350,\n",
      "         0.0336, 0.0396, 0.0241, 0.0239, 0.0331, 0.0337, 0.0337, 0.0240, 0.0187,\n",
      "         0.0247, 0.0188, 0.0189, 0.0343, 0.0236, 0.0351, 0.0336, 0.0330, 0.0243,\n",
      "         0.7027, 0.0237, 0.0338, 0.7022, 0.0349, 0.7026, 0.7027, 0.7022, 0.0351,\n",
      "         0.0245, 0.0332, 0.0337, 0.0240],\n",
      "        [0.0187, 0.0235, 0.0187, 0.7025, 0.0342, 0.7022, 0.0351, 0.0394, 0.7026,\n",
      "         0.0343, 0.0381, 0.0343, 0.7028, 0.0242, 0.0335, 0.0342, 0.0241, 0.0350,\n",
      "         0.0342, 0.0235, 0.0343, 0.0237, 0.0244, 0.0343, 0.7025, 0.0349, 0.0350,\n",
      "         0.0235, 0.0240, 0.0240, 0.0351, 0.0188, 0.0341, 0.0350, 0.0341, 0.0350,\n",
      "         0.0235, 0.0239, 0.0188, 0.0242],\n",
      "        [0.0350, 0.0341, 0.0237, 0.0340, 0.0237, 0.0350, 0.0343, 0.0234, 0.0341,\n",
      "         0.6999, 0.0236, 0.0235, 0.0344, 0.0187, 0.6999, 0.0187, 0.0344, 0.0344,\n",
      "         0.0237, 0.0344, 0.0344, 0.0237, 0.0343, 0.7034, 0.0236, 0.7028, 0.0237,\n",
      "         0.0337, 0.0350, 0.0245, 0.0336, 0.0341, 0.0336, 0.0337, 0.0336, 0.0187,\n",
      "         0.0237, 0.7035, 0.0237, 0.0344]], dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<DivBackward0>)\n",
      "beta: 32  epoch: 2000  loss: 166.2000607925312  F-norm: 101.90530067366366\n",
      "beta: 32  epoch: 3000  loss: 166.20006139534757  F-norm: 101.90985105639244\n",
      "beta: 32  epoch: 4000  loss: 166.20006080652644  F-norm: 101.90460740369744\n",
      "beta: 32  epoch: 5000  loss: 166.20006079261003  F-norm: 101.90535272033766\n",
      "beta: 32  epoch: 6000  loss: 166.20006079253142  F-norm: 101.90529946599956\n",
      "beta: 32  epoch: 7000  loss: 166.2000607925312  F-norm: 101.9053006153818\n",
      "beta: 32  epoch: 8000  loss: 166.20006079253125  F-norm: 101.9053006710708\n",
      "beta: 32  epoch: 9000  loss: 166.20006079253096  F-norm: 101.90530067205971\n",
      "beta: 32  epoch: 10000  loss: 166.2000607925312  F-norm: 101.9053007051862\n",
      "beta: 32  epoch: 11000  loss: 166.2000607925312  F-norm: 101.90530070552143\n",
      "beta: 32  epoch: 12000  loss: 166.20006079253136  F-norm: 101.9053006876768\n",
      "beta: 32  epoch: 13000  loss: 166.20006079253125  F-norm: 101.90530067101425\n",
      "beta: 32  epoch: 14000  loss: 166.2000607925313  F-norm: 101.90530067367507\n",
      "beta: 32  epoch: 15000  loss: 166.20006079253142  F-norm: 101.90530067354642\n",
      "beta: 32  epoch: 16000  loss: 166.20006079253125  F-norm: 101.90530067406434\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-dac40c307a53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#         beta = torch.ones([m, n], dtype=torch.float64)*(2**j)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# x = torch.tensor(.0, requires_grad=True)\n",
    "# y = (x-2)**2\n",
    "\n",
    "\n",
    "\n",
    "# optimizer = torch.optim.SGD([x], lr=0.0001)\n",
    "\n",
    "\n",
    "# initilizae\n",
    "# print(x,y)\n",
    "for j in range(10):\n",
    "#     if (j!=0):\n",
    "#         x.data = x.data/2\n",
    "#     temp = torch.norm(x)\n",
    "#     x.data = x.data/temp\n",
    "    for i in range(40000):\n",
    "        optimizer.zero_grad()\n",
    "        y, fnorm = myloss(x,0)\n",
    "        y.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "#         beta = torch.ones([m, n], dtype=torch.float64)*(2**j)\n",
    "#         A = torch.sigmoid(beta*x)\n",
    "#         Anorm = torch.sum(A*A,0)**0.5\n",
    "#         Anorm = Anorm.repeat(m,1)\n",
    "#         A = A/Anorm\n",
    "#         nt = -torch.log(1/A-1)/beta\n",
    "#         x.data = nt.data\n",
    "#         A = torch.sigmoid(beta*x)\n",
    "        if (i==1000):\n",
    "            print(A)\n",
    "#         temp = torch.norm(x)\n",
    "#         x.data = x.data/temp\n",
    "        \n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print('beta:',2**j,' epoch:',i + 1,' loss:',y.item(),' F-norm:',fnorm.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.5303e-48, 1.5944e-43, 1.0000e+00, 4.1059e-52, 6.3132e-49, 2.5352e-48,\n",
      "         6.3034e-49, 3.0049e-46, 1.0000e+00, 9.1961e-44, 9.7455e-46, 8.7638e-44,\n",
      "         1.0920e-48, 1.1228e-48, 1.8867e-43, 1.5690e-43, 1.0000e+00, 8.8292e-49,\n",
      "         2.0152e-43, 1.8122e-43, 2.0303e-43, 3.2677e-43, 3.6366e-52, 2.1366e-43,\n",
      "         3.4035e-52, 1.4732e-43, 8.7864e-49, 3.7110e-43, 1.5205e-48, 8.2233e-43,\n",
      "         9.8964e-49, 1.0000e+00, 3.3234e-43, 1.3522e-48, 3.3856e-43, 1.7365e-43,\n",
      "         1.8233e-43, 1.2532e-48, 4.3121e-52, 1.0000e+00],\n",
      "        [1.9120e-48, 7.5918e-43, 4.1784e-43, 8.0501e-43, 8.1741e-43, 1.9053e-48,\n",
      "         1.0193e-42, 1.0000e+00, 4.6827e-43, 1.0000e+00, 5.7285e-45, 1.0000e+00,\n",
      "         1.0929e-42, 1.9373e-42, 1.7009e-48, 1.4705e-42, 4.7799e-43, 1.9640e-48,\n",
      "         9.3038e-43, 1.8765e-48, 1.8901e-48, 1.0000e+00, 1.0429e-42, 1.7865e-48,\n",
      "         9.4075e-43, 2.8268e-48, 1.0118e-42, 8.4749e-43, 1.9564e-48, 3.1233e-48,\n",
      "         1.0500e-42, 4.4030e-43, 7.9390e-43, 9.2943e-43, 1.8254e-48, 1.7270e-42,\n",
      "         9.2385e-43, 1.8572e-48, 9.5322e-43, 5.2555e-43],\n",
      "        [1.0000e+00, 1.8184e-43, 2.4809e-42, 2.2324e-52, 9.4347e-49, 1.0000e+00,\n",
      "         6.4351e-49, 3.1768e-53, 1.7929e-48, 9.5583e-49, 2.7561e-45, 6.4625e-49,\n",
      "         8.5009e-49, 1.3952e-48, 6.0092e-43, 9.0469e-49, 6.6235e-43, 1.8932e-43,\n",
      "         2.0966e-43, 1.9499e-43, 2.1132e-43, 1.0000e+00, 7.9678e-49, 3.4354e-43,\n",
      "         1.7169e-48, 8.9044e-49, 1.9072e-43, 1.9829e-43, 1.0000e+00, 1.0000e+00,\n",
      "         6.4933e-49, 1.7379e-48, 1.7253e-43, 1.9334e-43, 1.9570e-43, 6.1632e-49,\n",
      "         1.9643e-43, 1.4062e-42, 1.7293e-48, 1.5223e-48],\n",
      "        [1.0000e+00, 8.5470e-44, 4.0790e-52, 1.0000e+00, 1.6738e-43, 3.6785e-52,\n",
      "         1.9534e-43, 8.9218e-46, 5.3597e-52, 1.7941e-43, 2.9634e-46, 1.8792e-43,\n",
      "         1.6018e-48, 1.7800e-48, 8.3117e-44, 1.6389e-43, 3.6666e-52, 9.2376e-49,\n",
      "         9.9954e-44, 2.0023e-43, 1.0578e-43, 7.9655e-49, 1.0000e+00, 1.9839e-43,\n",
      "         4.2169e-52, 3.1987e-43, 8.8671e-49, 1.8587e-43, 1.3259e-48, 1.3516e-48,\n",
      "         4.0895e-43, 1.0000e+00, 9.2787e-44, 8.8602e-49, 1.6698e-43, 3.9561e-43,\n",
      "         1.8956e-43, 1.1480e-48, 1.0000e+00, 2.5455e-48],\n",
      "        [2.1488e-43, 3.1479e-52, 1.0129e-43, 1.8312e-43, 1.6946e-43, 2.0071e-43,\n",
      "         1.5067e-48, 3.1970e-53, 1.8599e-43, 6.7843e-49, 3.3422e-46, 1.0000e+00,\n",
      "         1.1353e-48, 5.7547e-44, 9.5793e-44, 4.7486e-44, 8.1980e-49, 1.0000e+00,\n",
      "         2.3870e-48, 1.0000e+00, 1.0000e+00, 6.4199e-49, 8.3953e-49, 8.5183e-43,\n",
      "         1.0052e-43, 1.0136e-43, 1.9672e-48, 4.2170e-52, 4.0295e-43, 1.1451e-43,\n",
      "         2.2064e-48, 1.6343e-43, 4.1005e-52, 3.6299e-52, 1.0000e+00, 3.8841e-43,\n",
      "         2.4150e-48, 1.1677e-43, 1.0867e-43, 4.0691e-43],\n",
      "        [8.7784e-49, 2.0064e-42, 1.1786e-48, 1.1361e-48, 1.6766e-43, 3.0844e-43,\n",
      "         1.4218e-42, 9.3767e-46, 1.1480e-48, 1.9608e-43, 3.3056e-46, 8.3324e-49,\n",
      "         1.6367e-42, 4.4122e-43, 9.4423e-44, 9.3123e-44, 1.0000e+00, 1.0000e+00,\n",
      "         1.4575e-48, 1.7813e-48, 1.8197e-48, 1.6261e-43, 1.0000e+00, 6.6072e-49,\n",
      "         5.4223e-43, 1.8155e-43, 1.0000e+00, 1.7311e-48, 3.8623e-43, 2.1596e-43,\n",
      "         1.2528e-48, 2.3904e-52, 1.7078e-48, 1.0000e+00, 2.2346e-52, 6.5097e-49,\n",
      "         1.4341e-48, 4.4083e-43, 1.2248e-48, 1.3596e-48],\n",
      "        [9.8166e-49, 1.1492e-48, 5.7546e-49, 5.6543e-43, 1.0000e+00, 9.6233e-49,\n",
      "         1.0000e+00, 8.6683e-46, 9.4212e-49, 1.8233e-43, 3.1448e-53, 3.3598e-43,\n",
      "         8.4262e-43, 4.0681e-43, 6.3445e-49, 9.7811e-49, 9.1895e-49, 6.7501e-43,\n",
      "         8.1636e-49, 5.7038e-43, 1.2167e-48, 6.0034e-49, 6.8202e-43, 1.7765e-43,\n",
      "         3.0201e-43, 3.4581e-43, 3.4736e-43, 1.1626e-48, 1.0000e+00, 1.0473e-48,\n",
      "         1.0000e+00, 9.3456e-49, 2.3474e-52, 1.2840e-48, 1.1332e-48, 3.6759e-43,\n",
      "         2.9390e-43, 1.8901e-43, 3.1492e-43, 1.0000e+00],\n",
      "        [1.7546e-43, 1.0000e+00, 1.5769e-43, 6.4213e-49, 1.6688e-43, 6.8886e-49,\n",
      "         2.2481e-48, 8.5466e-46, 6.3284e-49, 1.8753e-43, 3.2306e-46, 1.0788e-48,\n",
      "         1.0000e+00, 2.3267e-43, 9.4124e-44, 9.1724e-44, 7.0141e-43, 2.4273e-48,\n",
      "         3.6895e-52, 1.0000e+00, 4.3458e-52, 1.6683e-43, 7.5635e-43, 8.8582e-49,\n",
      "         6.8672e-49, 1.8084e-43, 1.9529e-48, 1.0000e+00, 4.1145e-43, 2.3198e-43,\n",
      "         1.5662e-48, 1.4529e-43, 4.1846e-52, 2.3899e-48, 3.2385e-52, 8.6585e-49,\n",
      "         1.0000e+00, 2.3475e-43, 1.7510e-43, 3.8449e-43],\n",
      "        [9.4663e-49, 1.6657e-43, 7.3247e-49, 5.6649e-43, 1.2691e-48, 9.4290e-49,\n",
      "         4.4043e-43, 2.4902e-45, 2.9910e-43, 2.4003e-48, 4.3157e-53, 1.7977e-43,\n",
      "         4.4838e-43, 1.0000e+00, 3.6602e-52, 1.0000e+00, 1.7756e-43, 1.1009e-43,\n",
      "         8.8243e-49, 1.0625e-43, 1.0680e-43, 8.8241e-49, 4.1641e-43, 3.8000e-52,\n",
      "         1.2376e-48, 1.0000e+00, 8.9709e-49, 1.0389e-43, 9.9734e-49, 1.0000e+00,\n",
      "         2.1684e-43, 2.8253e-43, 9.8384e-44, 1.0802e-43, 4.9239e-44, 1.0000e+00,\n",
      "         8.8261e-49, 3.6923e-52, 1.2460e-48, 4.0480e-43],\n",
      "        [2.1052e-43, 2.2582e-52, 3.8435e-43, 1.7191e-43, 3.1997e-43, 1.9623e-43,\n",
      "         7.9684e-49, 7.7990e-46, 1.8659e-43, 8.2625e-49, 2.8560e-45, 6.6561e-43,\n",
      "         8.4163e-49, 1.2557e-48, 1.2127e-48, 1.2023e-48, 6.2950e-49, 1.5141e-48,\n",
      "         1.0000e+00, 1.8576e-48, 1.8695e-48, 1.6342e-43, 6.2398e-49, 1.0000e+00,\n",
      "         3.6043e-43, 2.4454e-52, 1.0000e+00, 1.8654e-48, 1.9155e-43, 9.4834e-49,\n",
      "         6.7440e-43, 1.6336e-43, 1.8036e-48, 1.5201e-48, 2.3092e-42, 1.0000e+00,\n",
      "         1.0000e+00, 1.2618e-48, 3.9254e-43, 1.9367e-43],\n",
      "        [1.0635e-43, 1.0000e+00, 9.9843e-44, 9.0371e-44, 8.4018e-49, 2.1221e-43,\n",
      "         1.0000e+00, 8.4792e-46, 1.8803e-43, 1.8616e-43, 8.7812e-46, 1.0531e-48,\n",
      "         1.6583e-48, 1.1854e-43, 1.8144e-43, 1.7781e-43, 7.5951e-43, 2.3927e-48,\n",
      "         1.0000e+00, 4.2376e-52, 1.0000e+00, 1.7313e-43, 3.6850e-43, 8.8196e-49,\n",
      "         1.0475e-43, 1.7865e-43, 1.9603e-48, 5.3336e-52, 9.3042e-49, 2.4002e-43,\n",
      "         3.6723e-52, 9.0317e-44, 1.0000e+00, 3.3401e-48, 4.0009e-52, 8.5991e-49,\n",
      "         3.6556e-52, 1.2134e-43, 5.3751e-44, 9.0117e-49],\n",
      "        [1.0450e-42, 4.4060e-43, 2.1231e-42, 2.0251e-43, 1.0000e+00, 1.0335e-42,\n",
      "         1.8609e-48, 5.5326e-45, 4.7659e-43, 2.3365e-48, 1.0000e+00, 4.2415e-43,\n",
      "         2.4673e-43, 3.5849e-48, 1.0000e+00, 1.0000e+00, 5.1544e-43, 2.6749e-43,\n",
      "         2.2125e-42, 2.5504e-43, 5.2243e-43, 1.7348e-42, 2.3176e-43, 3.6709e-48,\n",
      "         9.4314e-43, 5.3535e-52, 1.1061e-42, 5.3565e-43, 3.0615e-48, 4.1294e-48,\n",
      "         2.0067e-48, 4.4622e-43, 8.8519e-43, 5.6689e-43, 5.3256e-43, 3.5148e-48,\n",
      "         1.0481e-42, 3.7103e-48, 9.5844e-43, 1.9929e-48],\n",
      "        [2.4629e-48, 1.0311e-43, 1.0000e+00, 3.3093e-52, 3.2703e-43, 2.4840e-48,\n",
      "         9.8984e-44, 8.2771e-46, 3.4756e-52, 8.4375e-49, 2.8090e-45, 9.4157e-44,\n",
      "         1.2223e-48, 1.0000e+00, 1.2041e-48, 1.1414e-48, 1.6542e-48, 2.1525e-43,\n",
      "         2.1855e-43, 1.1164e-43, 6.1200e-44, 6.3478e-43, 1.5809e-48, 1.2429e-48,\n",
      "         1.0000e+00, 2.3511e-52, 8.3564e-43, 1.1039e-43, 7.7676e-43, 2.0093e-48,\n",
      "         1.0102e-43, 3.3876e-52, 5.6740e-44, 2.1579e-43, 5.7201e-44, 1.1717e-48,\n",
      "         4.1503e-43, 1.0000e+00, 1.0000e+00, 1.1836e-48],\n",
      "        [2.1456e-43, 3.9759e-52, 2.1136e-43, 1.6941e-43, 8.7483e-49, 2.0052e-43,\n",
      "         3.5843e-52, 8.5780e-46, 3.7682e-43, 9.3714e-44, 1.0655e-45, 1.5262e-48,\n",
      "         1.0991e-48, 5.8909e-44, 9.9900e-44, 9.8053e-44, 1.2568e-48, 3.6350e-52,\n",
      "         3.4263e-48, 4.2477e-52, 5.4008e-52, 1.7643e-43, 8.1240e-49, 4.2087e-43,\n",
      "         9.9107e-44, 5.1952e-44, 1.9891e-48, 1.0000e+00, 9.0819e-49, 1.1931e-43,\n",
      "         1.0000e+00, 3.2890e-43, 1.0000e+00, 1.0000e+00, 1.0000e+00, 4.0522e-43,\n",
      "         2.4624e-48, 6.0227e-44, 1.0703e-43, 1.3734e-48],\n",
      "        [3.7196e-52, 6.5946e-49, 3.3048e-52, 1.0000e+00, 1.6562e-43, 1.0000e+00,\n",
      "         4.1403e-43, 9.0698e-46, 1.0000e+00, 1.8128e-43, 2.9964e-46, 1.8155e-43,\n",
      "         1.0000e+00, 1.8250e-48, 8.3737e-44, 1.6521e-43, 1.5000e-48, 3.7964e-43,\n",
      "         1.7195e-43, 6.8537e-49, 1.8258e-43, 8.0157e-49, 2.1328e-48, 1.9110e-43,\n",
      "         1.0000e+00, 3.2252e-43, 3.5855e-43, 6.5312e-49, 1.3183e-48, 1.3585e-48,\n",
      "         3.8844e-43, 4.2194e-52, 1.5953e-43, 3.5680e-43, 1.5571e-43, 3.8069e-43,\n",
      "         6.5811e-49, 1.1763e-48, 4.3258e-52, 1.8268e-48],\n",
      "        [3.5829e-43, 1.6235e-43, 8.2445e-49, 1.4413e-43, 8.0635e-49, 3.5516e-43,\n",
      "         1.9627e-43, 3.0164e-53, 1.6135e-43, 1.0000e+00, 4.3095e-53, 6.3663e-49,\n",
      "         2.0477e-43, 3.7094e-52, 1.0000e+00, 3.6154e-52, 2.0045e-43, 2.1399e-43,\n",
      "         8.6152e-49, 2.0839e-43, 2.1065e-43, 8.7413e-49, 1.8942e-43, 1.0000e+00,\n",
      "         8.0817e-49, 1.0000e+00, 8.6712e-49, 1.0113e-43, 3.8042e-43, 2.4552e-48,\n",
      "         9.8913e-44, 1.5289e-43, 9.5545e-44, 1.0392e-43, 9.4597e-44, 3.6695e-52,\n",
      "         8.5931e-49, 1.0000e+00, 8.1355e-49, 2.1018e-43]], dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0.]], dtype=torch.float64, grad_fn=<RoundBackward>)\n",
      "tensor([[False, False,  True, False, False, False, False, False,  True, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False,  True, False, False, False, False, False, False, False,  True],\n",
      "        [False, False, False, False, False, False, False,  True, False,  True,\n",
      "         False,  True, False, False, False, False, False, False, False, False,\n",
      "         False,  True, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True, False, False, False, False,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False,  True, False, False, False, False, False, False,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [ True, False, False,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False,\n",
      "         False,  True, False, False, False, False, False, False,  True, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False,  True, False, False, False, False, False,  True, False,  True,\n",
      "          True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False,  True, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True,  True, False, False,\n",
      "         False, False,  True, False, False, False,  True, False, False, False,\n",
      "         False, False, False,  True, False, False, False, False, False, False],\n",
      "        [False, False, False, False,  True, False,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True, False,\n",
      "          True, False, False, False, False, False, False, False, False,  True],\n",
      "        [False,  True, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False,  True,\n",
      "         False, False, False, False, False, False, False,  True, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False,  True, False,  True, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False,  True,\n",
      "         False, False, False, False, False,  True, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True, False,\n",
      "         False, False, False,  True, False, False,  True, False, False, False,\n",
      "         False, False, False, False, False,  True,  True, False, False, False],\n",
      "        [False,  True, False, False, False, False,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True, False,\n",
      "          True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False,  True, False, False, False, False, False,\n",
      "          True, False, False, False,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False,  True, False, False, False, False, False, False, False,\n",
      "         False, False, False,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True, False, False,\n",
      "          True, False,  True,  True,  True, False, False, False, False, False],\n",
      "        [False, False, False,  True, False,  True, False, False,  True, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False,\n",
      "         False, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False,  True,\n",
      "         False, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False,  True, False,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True, False, False]])\n"
     ]
    }
   ],
   "source": [
    "beta = torch.ones([m, n], dtype=torch.float64)*(32)\n",
    "C = torch.sigmoid(beta*x)\n",
    "# print(C)\n",
    "# B is the final sensing matrix\n",
    "B=torch.round(C)\n",
    "torch.set_printoptions(threshold=5000)\n",
    "print(B)\n",
    "# print((B!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
